---
title: ""
author: ""
date: ""
output: pdf_document
---


$\rule{6.5in}{1pt}$
\begin{center}

\textbf{UNIVERSIDAD NACIONAL DE COLOMBIA}

\textit{IAA-Modulo 1}

\textbf{Autor:}

\textit{Daniela Pico}

\textit{Juan Sebastian Falcón}

\textit{Jhonatan Smith}

\textbf{Profesor:}

\textit{Juan Carlos Salazar}

\textbf{2021-02}
\end{center}

$\rule{6.5in}{1pt}$

```{r,echo=FALSE,warning=FALSE}
library(readr)
customer=read.table(file.choose(),header=T,sep=",")
```

**1) Considere el estadistico Leverage**

$$h_{ii}=\frac{1}{n}+\frac{(x_{i}-\overline{x})^{2}}{\sum_{j=1}^{n}(x_{j}-\overline{x})^{2}}$$

**Demuestre que**

\hspace{1cm}


$$\frac{1}{n}\leq h_{ii}\leq 1$$

\hspace{0.5cm}

Por el lado izquierdo 

\hspace{0.5cm}

Sabemos que la diferencia de cuadrados $(x_{i}-\overline{x})^{2}$ siempre va ser $\geq 0$ por tanto la sumatoria de las diferencias de cuadrados $\sum_{j=1}^{n}(x_{j}-\overline{x})^{2}$ tambien sera un numero $\geq 0$. Por lo tanto $\frac{(x_{i}-\overline{x})^{2}}{\sum_{j=1}^{n}(x_{j}-\overline{x})^{2}}\geq 0$. 
Luego, tomando el caso de que $x_{i}=\overline{x}$, tendriamos que 
$$h_{ii}=\frac{1}{n}+\frac{0}{\sum_{j=1}^{n}(x_{j}-\overline{x})^{2}}=\frac{1}{n}$$

\hspace{0.5cm}

Se demuestra que 

\hspace{0.5cm}

$$\frac{1}{n}\leq h_{ii}$$
\hspace{0.5cm}

Por el lado derecho

\hspace{0.5cm}

Tenemos la matriz Hat $H=X(X^{T}X)^{-1}X^{T}$, cuyas diagonales son los valores $h_{ii}$ 

Se tiene la matriz $\mathbf{H}$ como

$$H=\begin{bmatrix}
h_{11} & h_{12} & \cdots  & h_{1n}\\ 
h_{21} & h_{22} & \cdots  & \vdots \\ 
\vdots  & \vdots  & \ddots  & \vdots \\ 
h_{n1} & \cdots  & \cdots  & h_{nn}
\end{bmatrix}$$

Se sabe que la matriz Hat tiene las siguientes propiedades 
Es una matriz simetrica. $H=H^{T}$
Es una matriz idenpotente. $H=H^{2}$

A partir de las anteriores propiedades se soluciona $H^{2}$

$$ H^{2}=\begin{bmatrix}
h^{2}_{11}+\sum_{i\neq j}^{n}h^{2}_{ij} &\cdots  & \cdots  & \cdots \\ 
\vdots  & h^{2}_{22}+\sum_{i\neq j}^{n}h^{2}_{ij} & \cdots  & \vdots \\ 
\vdots  & \vdots  & \ddots  & \vdots \\ 
\vdots  & \cdots  & \cdots  & h^{2}_{nn}+\sum_{i\neq j}^{n}h^{2}_{ij}
\end{bmatrix}$$

\hspace{0.5cm}

Observando la diagonal principal de la matriz $H^{2}$ tendriamos que 

$$h_{ii}=h^{2}_{ii}+\sum_{i\neq j}^{n}h^{2}_{ij}$$

De lo anterior tendrimos que $h_{ii}$ es igual a su cuadrado mas una sumatoria, esto solo seria posible si $h_{ii}\geq  h^{2}_{ii}$, y esto a su vez implica que $h_{ii} \leq 1$.

\hspace{0.5cm}

Se demuestra que 

$$h_{ii} \leq 1$$
Finalmente 

$$\frac{1}{n}\leq h_{ii} \leq 1$$
\hspace{1cm}

**2) Considere el conjunto de datos anexo el cual tiene 17 variables. Asuma que el supervisor es la variable Loan**

a) Cree un conjunto de datos de entrenamiento del 75% y el restante 25 % tratelo como datos de test o de prueba


```{r}
bank <- read.csv(file.choose(), sep = ",")
```

Se procede a realizar la division de la base de datos.

```{r}
library(dplyr)
set.seed(1039705595) # Se selecciona una semilla para la extraccion de la muestra aleatoria
datab <- sort(sample(nrow(bank), nrow(bank)*.75))
# Datos de entrenamiento
train<-bank[datab,]
# Datos de prueba
test<-bank[-datab,]
ytrain<-bank[datab,8]
ytest<-bank[-datab,8]
newdata1<- train %>% dplyr::select(-8)
newdata2<- test %>% dplyr::select(-8)

```

b) Se ajusta Naive Bayes con los datos de entrenamiento. En R...

```{r echo=TRUE}
library(naivebayes)
modelo_NB <- naive_bayes(loan ~ ., data = train)

```

c) Para implementar Knn se debe utilizar variables indicadoras para las categoricas y normalizar las continuas. Tenga presente que de las 17 variables de la base de datos 9 (8 sin contar la supervisora) son categoricas.

Primero, se implementan las variables indicadoras (Dummies) y luego se normalizan las continuas. 

```{r echo=FALSE}
attach(bank)
library(class)
library(ISLR)
library(MASS)
library(Amelia)
library(pscl)
library(caret)
library(pROC)
library(ROCR)
library(wesanderson)
library(e1071)
library(mlbench)
library(InformationValue)
job_dummie<-fastDummies::dummy_cols(bank$job)
job_dummie<-job_dummie[-1]
marital_dummie<-fastDummies::dummy_cols(bank$marital)
marital_dummie<-marital_dummie[-1]
education_dummie<-fastDummies::dummy_cols(bank$education)
education_dummie<-education_dummie[-1]
colnames(education_dummie)<-c(".data_primary", ".data_secondary",
".data_tertiary", "data_unknown_education")
default_dummie<-ifelse(bank$default == "yes", 1, 0)
contact_dummie<-fastDummies::dummy_cols(bank$contact)
contact_dummie<-contact_dummie[-1]
colnames(contact_dummie)<-c(".data_cellular",".data_telephone","data_unknown_dummie")
month_dummie<-fastDummies::dummy_cols(bank$month)
month_dummie<-month_dummie[-1]
housing_dummie<-ifelse(bank$housing == "yes", 1, 0)
poutcome_dummie<-fastDummies::dummy_cols(bank$poutcome)
poutcome_dummie<-poutcome_dummie[-1]
colnames(poutcome_dummie)<-c(".data_failure",".data_other",".data_success",
".data_unknown_poutcome")
deposit_dummie<-fastDummies::dummy_cols(bank$deposit)
deposit_dummie<-deposit_dummie[-1]

```

Se construye un df con todas las variable para luego sacar de alli los datos de prueba y entrenamiento dada las indicadoras y las varuables normalizadas.

```{r include=FALSE}

newdata<-cbind(deposit_dummie,poutcome_dummie,month_dummie,housing_dummie,
contact_dummie,education_dummie,marital_dummie,job_dummie,default_dummie,
bank$age,bank$balance,bank$day,bank$duration,bank$campaign,bank$pdays, bank$previous,loan)
newdatasort <- sort(sample(nrow(newdata), nrow(newdata)*.75))

```

Dado el siguiente codigo, se normalizan las variables continuas, pues se requieren bajo la misma escala para proceder.

```{r}
normalize <- function(x) {
norm <- ((x - min(x))/(max(x) - min(x)))
return (norm)
}
train2<-(newdata[newdatasort,])
train2n<-normalize(train2[-50])
test2<-(newdata[-newdatasort,])
test2n<-normalize(test2[-50])
# Datos de entrenamiento para Knn
ytrain2<-newdata[newdatasort,50]
# Datos de prueba para Knn
ytest2<-newdata[-newdatasort,50]

```

Se simulan knn con k de 1 a 10

```{r}
for (i in 1:10) {
# Se modela con los datos de entrenamiento con un k=i
mod2train<- knn(train = train2n, test = train2n, cl = ytrain2, k=i, prob=TRUE)
# Se modela con los datos de prueba con un k=i
mod2test<- knn(train = train2n, test = test2n, cl = ytrain2, k=i,prob=TRUE)
tk<-table(mod2train,ytrain2)
t1n<-table(mod2test,ytest2)
# Training error
Training_error_KNN<-(tk[1,2]+tk[2,1])/(sum(tk))
print(table(Training_error_KNN,i))
}
```


Bajo estos criterios se escoge k = 3 puesto que tiene un error de entrenamiento bajo y un k mas pequeño puede estar sobre ajustando el modelo (como posiblemente sucede en k=1)

Se ajusta el modelo con el K seleccionado.

```{r}
modelo_knn<-knn(train = train2n, test = train2n, cl = ytrain2, k=3, prob=TRUE)

```

d) La Regresion logistica será tal que:

```{r}
modelo_logistico <- glm(as.factor(train2$loan) ~ . ,data=train2n, family = "binomial")

```

e) Se implementa LDA con R:

```{r}
# ytrain: variable loan con 1,0
newdata1<- train %>% dplyr::select(-8)
modelo_LDA=lda(ytrain~., data = newdata1)
```

f) Se calcula la matriz de confusion, el error de training MSE y se grafica. 

Todos los siguientes calculos a presentar seran dados con los datos de entrenamiento. 


```{r echo=FALSE}
train_NB<-predict(modelo_NB,newdata1,type="class")
predicted<-predict(modelo_logistico,newdata=train2n,type = "response")
optCutOff <- optimalCutoff(train2$loan, predicted)[1]
glm.pred <- ifelse(predicted > 0.48, 1, 0)
table(glm.pred,ytrain)
lda.class<-predict(modelo_LDA,newdata1,type=c("class"))$class
train_lda<-ifelse(ytrain==lda.class,0,1)
```


```{r}
# Modelo Naive Bayes
tabla_NB_E<-table(train_NB,ytrain)
tabla_NB_E
```


```{r}
# Knn
tabla_knn_E<-table(modelo_knn,ytrain)
tabla_knn_E
```


```{r}
# Modelo logistico
tabla_lo_E<-table(glm.pred,ytrain)
tabla_lo_E
```


```{r echo=FALSE}
# Modelo LDA
tabla_LDA_E<-table(train_lda,ytrain)
tabla_LDA_E
```

Las tablas anteriores son las respectivas matrices de confusion asociada a cada modelo. Note que los elementos de la diagonal principal son los aciertos de prediccion y cualquier elemento fuera de ella representa un error a la hora de predecir.

LDA es el modelo que mejor acierta a la hora de predecir, luego, seguiria Naive Bayes, Logistico y Knn en ultimo.


Se calcula el trainning MSE para cada modelo:

```{r echo=FALSE}
lista<-list(tabla_NB_E,tabla_knn_E,tabla_lo_E,tabla_LDA_E)
training_MSE<-NULL
for (i in lista) {
training_MSE<-c(training_MSE,(i[1,2]+i[2,1])/sum(i))
}
training_MSE<-data.frame(matrix(training_MSE,nrow = 1))
names(training_MSE)<-c("Naive Bayes","Knn","Logistico","LDA")
round(training_MSE,5)
```

Y se observa que el modelo con menor MSE es LDA.


Graficas ROC:

```{r echo=FALSE}
NB_E_ROC<-roc(response = ytrain, predictor = ifelse(train_NB=="yes",1,0))
knn_E_ROC<-roc(response = ytrain, predictor = as.numeric(modelo_knn))
logis_E_ROC<-roc(response = ytrain, predictor = glm.pred)
LDA_E_ROC<-roc(response = ytrain, predictor = train_lda)
par(mfrow=c(2,2))
plot(NB_E_ROC,main="Curva ROC para Modelo Naives Bayes \n (datos entrenamiento)",
col="blue")
legend("topleft",paste("Area",as.character(round(NB_E_ROC$auc,4)),sep = "="),
bty = "n")
plot(knn_E_ROC,main="Curva ROC para Modelo Knn \n (datos entrenamiento)",
col="blue")
legend("topleft",paste("Area",as.character(round(knn_E_ROC$auc,4)),sep = "="),
bty = "n")
plot(logis_E_ROC,main="Curva ROC para Modelo log´ıstico \n (datos entrenamiento)",
col="blue")
legend("topleft",paste("Area",as.character(round(logis_E_ROC$auc,4)),sep = "="),
bty = "n")
plot(LDA_E_ROC,main="Curva ROC para Modelo LDA \n (datos entrenamiento)",
col="blue")
legend("topright",paste("Area",as.character(round(LDA_E_ROC$auc,4)),sep = "="),
bty = "n")


```

El modelo que, mejor resultados ofrece a la hora de predecir segun la corva ROC es el modelo LDA. Basta ver la curva y su valor AUC de casi 100%.

g) La matriz de consfusion para los 4 modelos de prueba es:

```{r echo=FALSE}
test_NB<-predict(modelo_NB,newdata=newdata2,type="class")
test_knn<-knn(train = train2n, test = test2n, cl = ytrain2, k=2, prob=F)
pred<- predict(modelo_logistico,newdata = test2n,type = "response")
test_logs<-ifelse(pred >= 0.5, 1, 0)
lda.class_t<-predict(modelo_LDA,newdata2,type=c("class"))$class
test_LDA<-ifelse(ytest==lda.class_t,0,1)
tabla_NB_T<-table(test_NB,ytest)
tabla_knn_T<-table(test_knn,ytest)
tabla_lo_T<-table(test_logs,ytest)
tabla_LDA_T<-table(test_LDA,ytest)

```
Matriz de Naive Bayes

```{r echo=TRUE}
tabla_NB_T
```

Matriz de Knn

```{r echo=FALSE}
tabla_knn_T
```

Matris de Regresion Logistica

```{r echo=FALSE}
tabla_lo_T
```
En este resultado, el valor asignado a la segunda fila (1) es cero. Implicando 
que la matriz es de la 2x1, 2 columnas y una fila

Matriz LDA

```{r echo=FALSE}
tabla_LDA_T
```

Calculo del MSE para cada modelo:

Para Naiev Bayes

```{r}
MSE_NB_T = (tabla_NB_T[1,2]+tabla_NB_T[2,1])/sum(tabla_NB_T[,])
MSE_NB_T
```
Para Knn
```{r}
MSE_Knn_t = (tabla_knn_T[1,2]+tabla_knn_T[2,1])/sum(tabla_knn_T[,])
MSE_Knn_t
```
Para Regresion Losgistica:

```{r echo=TRUE}
MSE_RL =  (tabla_lo_T[1,2])/sum(tabla_NB_T[,])
MSE_RL 
```

Para LDA:

```{r echo=TRUE}
MSE_LDA = (tabla_LDA_T[1,2]+tabla_LDA_T[2,1])/sum(tabla_LDA_T[,])
MSE_LDA
```
El MSE mas pequeño es de LDA. 

Finalmente, graficas ROC:

```{r echo=FALSE}
NB_T_ROC<-roc(response = ytest, predictor = ifelse(test_NB=="yes",1,0))
knn_T_ROC<-roc(response = ytest, predictor = as.numeric(test_knn))
logis_T_ROC<-roc(response = ytest, predictor = test_logs)
LDA_T_ROC<-roc(response = ytest, predictor = test_LDA)
par(mfrow=c(2,2))
plot(NB_T_ROC,main="Curva ROC para Modelo Naives Bayes \n (datos prueba)",
col="blue")
legend("topleft",paste("Area",as.character(round(NB_T_ROC$auc,4)),sep = "="),
bty = "n")
plot(knn_T_ROC,main="Curva ROC para Modelo Knn \n (datos prueba)",
col="blue")
legend("topleft",paste("Area",as.character(round(knn_T_ROC$auc,4)),sep = "="),
bty = "n")
plot(logis_T_ROC,main="Curva ROC para Modelo log´ıstico \n (datos prueba)",
col="blue")
legend("topleft",paste("Area",as.character(round(logis_T_ROC$auc,4)),sep = "="),
bty = "n")
plot(LDA_T_ROC,main="Curva ROC para Modelo LDA \n (datos prueba)",col="blue")
legend("topright",paste("Area",as.character(round(LDA_T_ROC$auc,4)),sep = "="),
bty = "n")

```

H) El modelo con mejor desempeño fue el del modelo de LDA dada las estimaciones 
de sus parametros, teniendo en cuenta que fue el que mejor MSE ha tenido a lo largo
de todas las pruebas.


\hspace{1cm}

**3) Considere el conjunto de datos anexo el cual contiene 12 variables incluyendo ID. Asuma que el supervisor es la variable income.**

a) Cree un conjunto de datos de entrenamineto del 75%
 y el restante 25% tratelo como datos de test o de prueba.
 
```{r,echo=FALSE,warning=FALSE}
library(FNN)
set.seed(2224)
n = nrow(customer)
train_ind <- sample(1:n, size = round(0.75*n), replace=FALSE)
train <- customer[train_ind ,]
test <- customer[-train_ind ,]
```

b) Con los datos de entrenamiento implemente KNN (con al menos tres valores para K), usando icome como supervisor y debts como predictor, grafique e interprete.

Del Punto anterior se obtuvo una base de entrenamiento de 86 observaciones mientras que la base de prueba fue de 28, se usa función knn.reg de la libreria FNN para realizar la regresión de k-vecinos más cercanos. La variable respuesta income y su respectiva variable predictora debts.
En este caso se uso K= 4,8,12 y 16 respectivamente

```{r, echo=FALSE}
X_train <- train["debts"]
y_train <- train["income"]
X_test <- test["debts"]
y_test <- test['income']

par(mfrow=c(2,2))
for (i in 1:4){
X_train_seq <- data.frame(debts = seq(range(X_train$debts)[1], range(X_train$debts)[2],
by = 0.01))
fit.knn.train<-knn.reg(train = X_train, test = X_train_seq,y=y_train , k = 4*i)
plot(train$debts,train$income,col = "black",xlab = 'Debts',
ylab = 'income')
lines(X_train_seq$debts, fit.knn.train$pred,col="red4",type="S",lwd=1.5)

}
```

De las graficas anteriores se observa que cuando K=4 proporciona un ajuste flexible y con mayor variabilidad en comparación al resto de graficas y mientras mayor es el tamaño de k la linea roja tiende a ser mas suave, es decir que se logra una mejor tendencia cuando k se incrementa, por tanto se opta por el modelo de regresión con k=16, sin embargo se debe tener en cuenta que cuando k toma un valor muy elevado el suavizamiento puede incrementar el sesgo al enmascarar algo de la estructura de F(x).

c) Con los datos de entrenamiento, implemente regresion lineal simple usando income como el supervisor y dbts como predictor. Grafique e interprete.

```{r,echo=FALSE,warning=FALSE}
# Ajuste de modelo de RLS
y<- y_train$income
x <- X_train$debts
modelo <- lm(y ~ x)
summary(modelo)
plot(X_train$debts,y_train$income,col = "dodgerblue", main = "Regresion lineal simple",xlab = 'Debts', ylab = 'income')
abline(modelo,col="red4",type="S",lwd=1.5)

```
Se oberva:

1. La relación entre el número Debts y income se puede modelar por un MRLS ya que tiene una tendencia lineal.

2. Esta relación es del tipo creciente, esto es, a medida que aumenta el Debts el income aumenta.

3. La dispersion entre Debs y income es similar, sin embargo, se observa gran variabilidad.

4. El modelo lineal sigue la tendencia de los datos de entrenamiento, no pasa por toda lo nube de puntos, pero parece tener buen comportamiento de ajuste de los datos.

d) Use los repectivos ajustes de cada uno de los modelos anteriores y con el conjunto de prueba, calcule el TEST-MSE. ¿Qué observa?.


```{r, echo=FALSE}
library(kableExtra)
pd <- knn.reg(train = X_train, test=X_test , y=y_train , k = 4)
test.MSE.knn4 <- mean((y_test$income-pd$pred)^2)
pd8 <- knn.reg(train = X_train, test=X_test , y=y_train , k = 8)
test.MSE.knn8 <- mean((y_test$income-pd8$pred)^2)
pd12 <- knn.reg(train = X_train, test=X_test , y=y_train , k = 12)
test.MSE.knn12 <- mean((y_test$income-pd12$pred)^2)
pd16 <- knn.reg(train = X_train, test=X_test , y=y_train , k = 16)
test.MSE.knn16 <- mean((y_test$income-pd16$pred)^2)
pd1 <- predict(modelo , data.frame('x'=X_test$debts))
test.MSE.lm <- mean((y_test$income-pd1)^2)



x2 <- c("Knn regresión k=4","Knn regresión k=8","Knn regresión k=12","Knn regresión k=16","Regresión simple")
y <- c("4655926", "4632614", "4475809", "4220362", "3996076")
datos <- data.frame( x2,y)
kable(datos,align=c(rep('c',times=4)),
col.names = c("Tipo","MSE_test"),digits=3)%>%
  kable_styling(position = "center")%>%
  kable_styling(latex_options = "HOLD_position")
```

Según el MSE test el peor ajuste fue cuando se utilizo regresión con k=4, ya que como fue mencionado anteriormente este modelo genera problemas en la variabilidad, también se observa que los modelos que tienen mejor desempeño en el ajuste son el modelo de regresión con k=16 y el modelo de regresión lineal ya que tienen un valor de MSE test menor en comparación al resto de modelos, esto es de esperarse ya que cuando se desconoce a f(x) knn con valores de k grandes es casi igual que OLS cuando f(x) es lineal, por lo cual Knn resulta ser un buen competidor con la regresión lineal.


e) Usando todos los datos y regresión lineal multiple seleccione un modelo usando forward, backward y stepwise.


![](C:/Users/jhsga/OneDrive/Escritorio/acomodis_page-0001.jpg){width=width height=height}




Dek metodo backward se observa una leve menoria en el AIC, además tiende a ser más pausible porque deja de estimar un parametro, mientras que con los metodos forward y stepwise se una la misma cantidad de parametros para hacer las estimaciones y predicciones.

e) Seleccione uno de los modelos del paso anterior y responda con argumentacion la
pregunta: ¿ajusta bien dicho modelo?

Vamos a seleccionar el modelo deacuerdo al metodo ”forward” que tiene un R2adj = 0.9587, a continuación se validaran los supuestos del modelo

![](C:/Users/jhsga/OneDrive/Escritorio/supuestos.PNG){width=width height=height}

* Se observa varianza aproximadamente constante ya que los errores oscilan alrededor del
cero de forma aleatoria, es decir, no siguen ningun patrón.

* En el Q-Q plot parece haber algunos outliers que nos hacen alertar sobre
el supuesto de normalidad, y las colas no parecen ajustarse correctamente a la recta, sin embargo el 95% de puntos se ajusta la recta, por tanto, se cumple el supuesto de normalidad en los errores.

* Se identifican igualmente los puntos con leverage que podrían afectar el ajuste. 

* En general, se concluye que aunque hay problemas con puntos atipicos y leverage, no parecen ser significativos, por tanto, se puede decir que el modelo hace un buen ajuste.
