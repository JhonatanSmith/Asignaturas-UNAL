---
title: "Clase 4"
author: "Jhonatan Smith Garcia"
date: "18/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# CLASE 4:

```{r}
require(ISLR)
```
```{r}
dim(Hitters) # Tiene 322 datos en 20 columnas (variables)
```
```{r}
names(Hitters)
```

La base de datos corresponde a unos jugadores de baseball. vamos a intentar seleccionar el modelo optimo con estas paruables

```{r}
Hitters = na.omit(Hitters) # Se eliminan NA's
dim(Hitters)
```
Esta es la nuva base de datos.

```{r}
sum(is.na(Hitters)) # En efecto, ya no hay NA's
```

```{r}
require(leaps)
```

NOTA: Lo recomendable no es quitar los valores faltantes. Puesto que esto afectará el rendimiento de la base de datos. Para hacer esto, hay que hacer un propio analisis de datos faltantes

El analisis de interes es ver la relacion del salario de los jugadores acorde al siguiente grupo de variables

```{r}
attach(Hitters)
# Salary ~. es un modelo con todas las variables
# nvmax es el numero maximo de variables aprobar por el modelo
regfit.full = regsubsets(Salary~., data = Hitters, nvmax =19)
reg.summary = summary(regfit.full)
```
La funcion regsubset me permite hacer todos los posibles modelos con todas las 19 variables.

```{r}
names(reg.summary)
```

Estas son las medidas, va a encontrar el modelo con 0, 1,2 ,3,...,19 variables. 

Luego, por alguno de estos criterios anteriores, va a seleccionar uno de esos modelos. 

# Analisis grafico:

```{r}
par(mfrow = c(1,2)) # Divide ventana de graficos en 2
plot(reg.summary$rss, xlab = "# variables", ylab = "RSS", type = "l")
plot(reg.summary$adjr2, xlab = "# variables", ylab = "Adj Rsqr", type = "l")
ai = which.max(reg.summary$adjr2)
points(ai, reg.summary$adjr2[ai], col = "red", cex = 2, pch = 20)

```

Ese punto de color rojo es un modelo con aprox 11 variables. Veamos otros metodos.

```{r}
par(mfrow =c(1,2))
plot(reg.summary$cp ,xlab =" Number of Variables", ylab="Cp", type="l")
a2<-which.min(reg.summary$cp)
points (a2, reg.summary$cp [a2], col ="red",cex =2, pch =20)
a3<-which.min(reg.summary$bic)
plot(reg.summary$bic ,xlab=" Number of Variables",ylab=" BIC",type="l")
points (a3, reg.summary$bic [a3], col =" red",cex =2, pch =20)

```

De esta manera se puede comparar el rendimiento segun los criterios de cada modelo. 

Ahora:

*Para el R^2 crudo*

```{r}
plot(regfit.full, scale ="r2")
```

Los cuadros llenos, significa que consideró a la variable, Segun eso, el mejor es el modelo con todas las variables.
El 2 entre mas variable, mas aumenta entonces no tiene sentido mirar este metodo
*PAra el R^2 ajustado*

```{r}
plot(regfit.full, scale ="adjr2") 
```
El ajustado si penaliza el numero de varriables. Se busca el valor mas alto que vendria siendo la primer fila. Es consistente con el criterio que selecciona 11 variables.

*BIC* Aca se busca el mas pequeño.

```{r}
plot(regfit.full, scale ="bic")

```

Este metodo selecciona un modelo con 7 variables. Y asi sucesivamente

# Problema:

Suponga que se llega a 3 modelos, cada uno con 4 variables diferentes entre si pero en ultimas, 4 variables. Como escogemos el mejor modelo? Cual es mejor?

# Rta: 
Utilice validacion cruzada (cross validation) y con esto, compara los modelos entre si. Se recomienda k-fold para cada uno de estos modelos. Y se mira quien tiene mejor rendimiento

# Metodo de seleccion hacia adelante (Forward)

Se hacen los mismos analisis que en los otros.

```{r}
regfit.fwd<-regsubsets(Salary~.,data=Hitters,
nvmax=19, method = "forward")
summary(regfit.fwd)

```
```{r}
plot(regfit.fwd, scale ="r2")

```
```{r}
plot(regfit.fwd, scale ="adjr2") 
```

Los metodos son consistenets entre si. Asi se selecciona la mejor modelo.

# Seleccion del mejor modelo con CV (Validacion Cruzada):

```{r}
set.seed (1)
train<-sample (c(TRUE ,FALSE), nrow(Hitters),rep=TRUE) # Aqui se divide en datos de entrenamiento y prueba pero no se maneja la proporcionde entrenamiento y prueba. Se deja tambien aleatorio
test<-(!train )
regfit.best<-regsubsets(Salary~.,data=Hitters[train,],
nvmax =19) # Se hace un modelo con los datos de entrenammiento
```

Se crea una funcion que es la que ayudara a decidir que modelo es el mejor

A TENER EN CUENTA: 
Si la base de datos es muy grande, lo recomendable seria utilizar este metodo de tru y false, puesto que esto es como tirar un moneda. 

el codigo test = (!train) el simobolo de exclamacion niega el valor de verdad asi que, se selecciona el complemento de train

```{r}
# Creando una función para evaluar los modelos:
predict.regsubsets =function (object,newdata,y){
form<-as.formula(object$call[[2]])
mat<-model.matrix(form ,newdata)
val.errors =rep(NA, (ncol(mat)-1))
for(i in 1:length(val.errors)){
coefi<-coef(object ,id=i)
xvars<-names (coefi)
pred<-mat[,xvars]%*%coefi
val.errors [i]= mean((y-pred)^2) # Este es el MSE de prueba
}
val.errors
}

```

Aqui se seleccionará el mejor modelo con CV

```{r}
set.seed(1)
e1<-predict.regsubsets(regfit.best,Hitters[test,],
Hitters$Salary[test]) # Calcula el MSE del modelo de prueba
b1<-which.min(e1) # Escoge el menor MSE
regfit.best<-regsubsets(Salary~.,data=Hitters ,nvmax =19) # MSE de todos los datos 
e1 # Vector de los errores
b1 #
```
Segun esto, el mejor e1 es del 10

```{r}
coef(regfit.best,10)

```
*Vamos con K-FOld*

```{r}
k<-10
set.seed (1)
folds<-sample (1:k,nrow(Hitters ),replace =TRUE) # Una forma aleatoria de dividir los pliegues. No se controla cuantos individuos hay en cd grupo
cv.errors<-matrix (NA ,k,19,
dimnames =list(NULL,paste (1:19))) # Se genera matriz vacia con k filas y 19 columnas
for(j in 1:k){
best.fit<-regsubsets(Salary~.,data=Hitters[folds!=j,],
nvmax=19)
pred<-predict.regsubsets(best.fit, Hitters[folds==j,],
Hitters$Salary[folds==j])
cv.errors[j,]<-pred
}
mean.cv.errors<-apply(cv.errors,2,mean) # Aply es una funcion que aplica la fn que se le indique, en este caso, medias y el "2" representa que se hace dicha funcion por columnas. Si en vez de 2 fuese 1, el proceso por filas
mean.cv.errors

```
Esta tabla representa el MSE para cada numero de variables. Ejemplo:

El MSE con 10 variables ede 11.22 y asi para todo el mundo

```{r}
c1<-which.min(mean.cv.errors)
plot(mean.cv.errors,type="b")

```
Segun esto el mejor modelo es el que tiene 10 variables

```{r}
reg.best<-regsubsets(Salary~.,data=Hitters, nvmax =19)
coef(reg.best,c1)

```

Este seria el mejor modelo, el que tiene estas 10 variables.