---
title: "Base datos 1"
author: "Jhonatan Smith Garcia"
date: "22/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# primer Ejercicio con base de datos 1

```{r}
datos = read.table(file = "C:/Users/jhsga/OneDrive/Escritorio/Estadistica/Introduccion a la analitica/Modulo 2/Scripts de practicas/Practica clase 5/Actividad clase 5/BASE_DATOS_2.txt", header = TRUE)
```

Se sabe que la base de datos a importar es de un tamaño considerable. Se asigna dicha
base de datos a la varuable homonima.


Se propone realziar un analisis con regresion lasso y ridges regression para analizar cuales son las
variables significativas del modelo. 

Note que la dimension de la base de datos es relativamente grande donde, p es # de variables y n
son la cantidad de observaciones.

```{r}
dim(datos)
```

Hay 13439 observaciones y 1328 varriables. Intentar hacer predicciones de Y con 1329 variables
es un proceso complejo. Por tanto, se propone realizar un proceso para asi prevenir que existan 
problemas de multicolinealidad entre variables. Cosa que es muy probable.

```{r}
df = data.frame(datos)
require(ISLR)
require(glmnet)
```


```{r}
data = na.omit(df)
X = model.matrix(Y~.,data = data)[,-1] # Matriz de diseño 
Y = data$Y # Vector variable rta
```

```{r}
gridz = 10^seq(-1,10, length = 100) # Seleccion aleatoria de un valor de lambda par aplicar CV
```

```{r}
modelo.ridge = glmnet(X,Y,alpha = 0, lambda = gridz) # Modelo ridge
```


```{r}
dim(coef(modelo.ridge))
```

Hay un total de 100 posibles valores asignados para cada posible modelo.

1329 variables e intercepto, y para cd valor de lambda estima los parametros.

```{r}
plot(modelo.ridge, xvar = "lambda", label = TRUE)

```

Se observa que los coeficientes correspondientes a las variables 8,119, 1000 son los significativos en un MRL puesto que cuando lambda tiende a cero, estos seran los valores significativos para los parametros estimados de beta_j



# Validazcion cruzada para la seleccion de lamba mas optimo

```{r}

set.seed(1998)
train1 =  sample(1:nrow(X), nrow(X)*0.7 ) # DAtos entrenamiento
test1 = -train1 # Datos de prueba
y.prueba = Y[test1]
```

Para realizar la validacion cruzada entre los conjuntos de prueba y entrenamiento, se haec lo sgt.

```{r}
cv.out = cv.glmnet(X[train1,], Y[train1], alpha = 0,) # Esta es la CV para los alfas
```


```{r}
plot(cv.out)
```

El aca calcula el MSE para todos los posibles valores edl logaritmo de lambda. Nos interesa aquellos donde la fn toma valores mas pequeños, osea, donde el MSE sea menor. 

Está muy proximo al log de 0. POr tanto, vamos a pedirle que nos suelte el valor de lamba solicitado.

```{r}
paco =cv.out$lambda.min
paco
```
El valor para el lamba obtimo segun validacion cruzada es este.

 *Verificando con datos de prueba*
 
```{r}

predicion.ridget = predict(modelo.ridge,s=paco, newx = X[test1,])

MSE.predic = mean((predicion.ridget-y.prueba)^2) # MSE del nuevo modelo
MSE.predic

```
 Este es el MSE dado por el metodo de Ridget. Ahora, ¿cual seria el modelo con 
 las varuables a trabajar?
 
#Seleccion de variables
 
```{r}
out = glmnet(X,Y, alpha = 0) # Ajuste el modelo
coef.mod.ridget = predict(out, s = paco, type = "coefficients")[1:144,]
coef.mod.ridget
```
 

```{r}
coef.mod.ridget[abs(coef.mod.ridget)>=0.05]
```


NO ES PRACTICO BUSCAR DE ESAS 1238 vbles cuales son cercanas a cero... Podria recorrerse con un condicional una a una y dado un valor especifico, que la descarte sin embargo, ese valor se selecciona arbitrareamente. Pero suponga que las que sean menos a |0.005| serán descartadas entonces...



# METODO DE SELECCION POR LASSO

```{r}
modelo.lasso = glmnet(X,Y,alpha = 1, lambda = gridz) # Modelo lasso
```


```{r}
plot(modelo.lasso, xvar = "lambda", label = TRUE)
```

```{r}
cv.out.lasso = cv.glmnet(X[train1,], Y[train1], alpha = 1,) # Esta es la CV para los alfas lasso
```

```{r}
plot(cv.out.lasso)
```
```{r}
lambda.lasso = cv.out.lasso$lambda.min
lambda.lasso
```
*Verificando con datos de prueba*
 
```{r}

predicion.lasso = predict(modelo.lasso,s= lambda.lasso, newx = X[test1,])

MSE.predic = mean((predicion.lasso-y.prueba)^2) # MSE del nuevo modelo
MSE.predic

```
 Este es el MSE dado por el metodo de Ridget. Ahora, ¿cual seria el modelo con 
 las varuables a trabajar?
 
 LASSO TIENE MEJOR MSE. SE TRABAJA CON LASSO
 
#Seleccion de variables
 
```{r}
out.lasso = glmnet(X,Y, alpha = 1) # Ajuste el modelo
coef.mod.lasso = predict(out.lasso, s = lambda.lasso,  type = "coefficients")[1:144,]
```


```{r}
coef.mod.lasso
```

```{r}
coef.mod.lasso[coef.mod.lasso!=0]
```




