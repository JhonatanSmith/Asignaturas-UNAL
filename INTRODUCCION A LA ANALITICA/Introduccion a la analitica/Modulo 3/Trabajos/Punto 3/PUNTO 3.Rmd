---
title: "punto 3 analitica"
author: "Daniela Pico Arredondo"
date: "31/1/2022"
output: pdf_document
---

**(3). Este ejercicio utiliza el conjunto de datos OJ el cual es parte de la libreria ISLR. Cree un conjunto de entrenamiento con una muestra aleatoria de 800 observaciones y un conjunto de prueba que conste del resto de observaciones**

```{r, warning=FALSE}
library(ISLR)
set.seed(10100)
train <- sample(nrow(OJ), 800)
OJtrain <- OJ[train, ]
OJtest <- OJ[-train, ]
```

**(b). Ajuste un clasificador de soporte vectorial utilizando cost=0.1, con Purchase como la variable respuesta y las demás como predictoras. Utilice la función summary() para obtener un resumen estadistico y describa los resultados obtenidos.**

```{r,warning=FALSE}
library(e1071)
svml <- svm(Purchase ~ ., data = OJtrain,
kernel = 'linear',
cost = 0.01)
summary(svml)
```
El clasificador de vectores de soporte crea 446 vectores de soporte de 800 puntos de
entrenamiento. De estos, 223 pertenecen al nivel CH y los 223 restantes pertenecen al nivel MM.

**(c). ¿Que tasas de entrenamiento y de prueba se obtienen?**
```{r, warning=FALSE}
library(kableExtra)
train.pred <- predict(svml, OJtrain)
t<-table(OJtrain$Purchase, train.pred)
kable(t)
Training_error<-(t[1,2]+t[2,1])/(sum(t))
kable(Training_error)
test.pred <- predict(svml, OJtest)
t2<-table(OJtest$Purchase, test.pred)
kable(t2)
Test_error<-(t2[1,2]+t2[2,1])/(sum(t2))
kable(Test_error)
```
La tasa de error de entrenamiento es aproximadamente 18.12% y la tasa de error de la prueba es aproximadamente 14.44%, en este caso para el conjunto de prueba se obtuvo una mejor tasa.

**(d). Utilice la función tune() para obtener un valor optimo de parametro cost. considere valores en el rango de 0.01 a 10**

```{r}
set.seed(1234)
tune<- tune(svm, Purchase ~ ., data = OJtrain, kernel = "linear",
ranges = list(cost =seq(0.01, 10, length.out = 40)))
summary(tune)
```
El mejor costo es de 1.2907692, ya que se obtuvo un error de 0.18125 Aunque tambien se encontro este error para costo de 0.7784615 y ambos tienen casi la misma variablidad.

**(e). Calcule de nuevo las tasas de error de entrenamiento y de prueba usando el valor optimo de cost obtenido**

```{r}
svmt <- svm(Purchase ~ ., kernel = "linear", data = OJtrain,
cost = tune$best.parameter$cost)
train.pred <- predict(svmt, OJtrain)
t3<-table(OJtrain$Purchase, train.pred)
kable(t3)
train_error<-(t3[1,2]+t3[2,1])/(sum(t3))
kable(train_error)
test.pred <- predict(svmt, OJtest)
t4<-table(OJtest$Purchase, test.pred)
kable(t4)
test_error<-(t3[1,2]+t3[2,1])/(sum(t3))
kable(test_error)
```
Tanto la tasa de error como de entrenamiento son aproximadamente 17.5 %, que se encuentra
en el rango de las tasas halladas en el numeral c

**(f) Repita items de (b) hasta (e) ajustando esta vez una maquina de soporte vectorial un nucleo radial. Utilizando el valor default** $\gamma$

```{r}
calc_error_rate <- function(svm_model, dataset, true_classes) {
confusion_matrix <- table(predict(svm_model, dataset), true_classes)
return(1 - sum(diag(confusion_matrix)) / sum(confusion_matrix))
}
svmradial <- svm(Purchase ~ . , data = OJtrain, kernel = "radial")
summary(svmradial)
```
El clasificador de vectores de soporte crea 384 vectores de soporte de 800 puntos de
entrenamiento. De estos, 187 pertenecen al nivel CH y los 197 restantes pertenecen al nivel MM.

```{r}
train.pr <- predict(svmradial, OJtrain)
t4<-table(OJtrain$Purchase, train.pr)
train_error<-(t4[1,2]+t4[2,1])/(sum(t4))
kable(train_error)
test.pr <- predict(svmradial, OJtest)
t5<-table(OJtest$Purchase, test.pr)
test_error<-(t5[1,2]+t5[2,1])/(sum(t5))
kable(test_error)

cat("Tasa de error de entrenamiento:", 100 * calc_error_rate(svmradial,
OJtrain, OJtrain$Purchase), "%\n")

cat("Tasa de error de prueba:", 100 * calc_error_rate(svmradial,
OJtest, OJtest$Purchase), "%\n")
```
**(g). Repita intems (b) hasta (e) utilizando nuevamente una maquina de soporte vectorial pero esta vez con un nucleo polinomial, usando degree=2**

```{r}
set.seed(1234)
svmG <- svm(Purchase ~ . , data = OJtrain, kernel = "poly", degree = 2)
summary(svmG)
cat("Tasa de error de entrenamiento:", 100 * calc_error_rate(svmG, OJtrain,
OJtrain$Purchase), "%\n")
cat("Tasa de error de prueba:", 100 * calc_error_rate(svmG, OJtest,
OJtest$Purchase), "%\n")
```

```{r}
set.seed(1234)
tune2 <- tune(svm, Purchase ~ . , data = OJtrain, kernel = "poly", degree = 2,
ranges = list(cost = seq(0.01, 10, length = 100)))
summary(tune2)
```
El mejor costo es de 6.9727273, ya que se obtuvo un error de 0.18.

```{r}
svm2 <- svm(Purchase ~ . , data = OJtrain, kernel = "poly", degree = 2,
cost = tune2$best.parameters$cost)
cat("Tasa de error de entrenamiento:", 100 * calc_error_rate(svm2, OJtrain,
OJtrain$Purchase), "%\n")
cat("Tasa de error de prueba:", 100 * calc_error_rate(svm2, OJtest,
OJtest$Purchase), "%\n")
```

**(h). En general cual metodo parece proporcionar los mejores resultados en estos datos**

El kernel de base radial en este ejemplo da las tasas mas pequeñas tanto para lod datos de entrenamiento como de prueba.

