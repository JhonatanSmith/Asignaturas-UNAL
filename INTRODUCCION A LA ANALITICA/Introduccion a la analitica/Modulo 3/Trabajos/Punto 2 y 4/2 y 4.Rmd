---
title: "Smith"
author: "Jhonatan Smith Garcia"
date: "2/2/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Punto 2)

MSVs - aplicado) En este ejercicio, se utilizará el enfoque de máquinas de soporte vectorial para predecir si un automóvil determinado posee un alto o bajo consumo de combustible basado en el conjunto de datos Auto (librería ILSR).


```{r warning=FALSE}
#librerias
library(e1071)
library(ISLR)

```

**a)** Cree una variable binaria que tome un 1 para automóviles con millaje por galón por encima de la mediana, y un 0 para automóviles 
con millaje por debajo de la mediana.

```{r}
data(Auto)

m <- median(Auto$mpg) # Calculo de la mediana 
y <- ifelse(Auto$mpg>m, 1,0) # Si la vble mpg>mediana, agregue 1, si no, agregue 0
y <- as.factor(y) # asigna a la vble creada como categoria, no como numero
dat<- data.frame(Auto,y) # Se crea el nuevo Dataset
```

**b).** Ajuste un clasificador de soporte vectorial a los datos con varios valores del parámetro cost para predecir si un automóvil posee millaje altomo bajo. Informe los errores de validación cruzada asociados con diferentes valores de este parámetro. Comente sobre sus resultados.

```{r}

#validacion cruzada para mirar el mejor smv con varios valores para cost
set.seed(32668)
vec <- tune(svm ,y~.,data=dat ,kernel ="linear",
              ranges =list(cost=c( 0.01, 0.1,0.5, 1,10,100,1000) ))
```

```{r}
summary(vec)
```

Con cost = 1 se obtiene el menor error de validación cruzada, el cual fue 0.007692308.

**c)** Ahora repita el inciso anterior, esta vez utilizando una máquina de soporte vectorial (svm) con una base de kernels radiales y polinomiales, con diferentes valores de los hiperparámetros cost, gamma o degree según el kernel y . Comente sus resultados.

**kernel radial**
```{r}
set.seed(23522)
vec <- tune(svm , y~., data=dat, kernel = "radial",
              ranges=list(cost=c(0.1,1,10,100,1000),
                          gamma=c(0.5,1,2,3,4) ))

```
```{r}
summary(vec)
```

Con varios valores para cost (10, 100,1000) y gamma=0.5 proporciona el menor error de validación cruzada, el cual fue 0.04596154.

**kernel polinomial**
```{r}
set.seed(8527)
tune.out=tune(svm , y~., data=dat, kernel = "polynomial",
              ranges=list(cost=c(0.01,0.1,1),degree=c(2,3,4),
                          gamma=c(0.5,1,2,3) ))
```
```{r}
summary(tune.out)
```

Con cost=0.1, gamma=2 y degree=3 proporciona el menor error de validación cruzada, el cual fue 0.04096154.

**d)** Realice algunos plots que sirvan de apoyo a sus afirmaciones en (b) y (c). Recomendación: En el lab, se utilizó la función plot() para objetos svm solo en casos con p = 2. Cuando p > 2, se puede utilizar la función plot() para crear gráficos que muestran pares de variables a la vez.

```{r}

#modelo ajustado kernel linear
svm1 =svm(y~., data=dat, kernel = "linear",cost=1)

```

```{r , echo=FALSE,fig.width=4, fig.height=3}

plot(svm1, data = dat, mpg~horsepower,col=c("azure","yellow"))
plot(svm1, data = dat, mpg~cylinders,col=c("azure","yellow"))
plot(svm1, data = dat, mpg~displacement,col=c("azure","yellow"))
plot(svm1, data = dat, mpg~weight,col=c("azure","yellow"))
plot(svm1, data = dat, mpg~acceleration,col=c("azure","yellow"))
plot(svm1, data = dat, mpg~year,col=c("azure","yellow"))
plot(svm1, data = dat, mpg~origin,col=c("azure","yellow"))
```


En los gráficos anteriores se observa como clasifica svm  para las diferentes variables tomando de a dos, con el valor de cost que dio el error más bajo en la validación cruza.

```{r}
#modelo ajustado  kernel radial
svm2 =svm(y~., data=dat, kernel ="radial",cost=10,gamma=0.5)

```

```{r echo=FALSE,fig.width=4, fig.height=3}

plot(svm2, data = dat, mpg~horsepower,col=c("azure","yellow"))
plot(svm2, data = dat, mpg~cylinders,col=c("azure","yellow"))
plot(svm2, data = dat, mpg~displacement,col=c("azure","yellow"))
plot(svm2, data = dat, mpg~weight,col=c("azure","yellow"))
plot(svm2, data = dat, mpg~acceleration,col=c("azure","yellow"))
plot(svm2, data = dat, mpg~year,col=c("azure","yellow"))
plot(svm2, data = dat, mpg~origin,col=c("azure","yellow"))
```

En los gráficos anteriores se observa como clasifica svm  para las diferentes variables tomando de a dos, con el valor de cost=10 y gamma=0.05 que fue primero que se detectó con el error más bajo en la validación cruza.

```{r}

#modelo ajustado  kernel polinomial
svm3 =svm(y~., data=dat, kernel="polynomial",
          cost=0.1,gamma=2,degree=3)
```

```{r echo=FALSE,fig.width=4, fig.height=3}

plot(svm3, data = dat, mpg~horsepower,col=c("azure","yellow"))
plot(svm3, data = dat, mpg~cylinders,col=c("azure","yellow"))
plot(svm3, data = dat, mpg~displacement,col=c("azure","yellow"))
plot(svm3, data = dat, mpg~weight,col=c("azure","yellow"))
plot(svm3, data = dat, mpg~acceleration,col=c("azure","yellow"))
plot(svm3, data = dat, mpg~year,col=c("azure","yellow"))
plot(svm3, data = dat, mpg~origin,col=c("azure","yellow"))

```

En los gráficos anteriores se observa como clasifica svm para las diferentes variables tomando de a dos, con el valor de cost=0.1, gamma=2 y degree=3 que fue uno de los que se detectó con el error más bajo en la validación cruza.

## 4 punto

```{r echo=T, message=FALSE, warning=FALSE}
#librerias
library(FactoMineR)#PCA 
library(factoextra)
library(gridExtra)#par
library(kableExtra)#tablas
library(dplyr)
```

[PCA, K-medias] En este ejercicio Ud va a generar un conjunto simulado de datos y entonces aplicará PCA y agrupamiento por k-medias sobre dichos datos.

**a)** 

Genere un conjunto de datos simulados con 20 observaciones en cada una de tres clases (es decir, 60 observaciones en total) y 50 variables.
Sugerencia: hay una serie de funciones en R que puede utilizar para generar datos. Un ejemplo es la función rnorm(); runif() es otra opción. Asegúrese de agregar un cambio en la media en las observaciones de cada clase a fin de obtener tres clases distintas.

Primero se fija una semilla que permita la reproductibilidad de los datos obtenidos y luego con ayuda de la función rnorm() y runif() se simula una base de datos con 50 variables, 60 observaciones y 3 clases de población:

```{r}
set.seed(1998)
df<- data.frame(matrix(nrow=60,ncol = 50))
for(i in 1:50){
  a=rnorm(n = 20,52,3)
  b=rnorm(n = 20,72,5)
  c=runif(n = 20,min = 30,max = 55)
  df[,i] <- c(a,b,c)
}
df$clase <- c(rep("1",20),rep("2",20),rep("3",20))
```

A continuación, se puede apreciar la estuctura general, con las primeras y últimas filas y también columnas:

```{r echo=FALSE}
kbl(
  rbind(
  cbind(head(df[,c(1,2)],3), "X-"="........",head(df[,c(50,51)],3)),
  "........",
  cbind(tail(df[,c(1,2)],3), "X-"="........",tail(df[,c(50,51)],3)))
  ) %>% kable_styling()
   
```


**b)** 

Realice PCA en las 60 observaciones y grafique las observaciones en términos de las 2 primeras variables principales Z1 y Z2. Use un color diferente para indicar las observaciones en cada una de las tres clases. Si las tres clases aparecen separados en esta gráfica, solo entonces continúe con la parte (c). Si no, vuelva al inciso a) y modifique la simulación para que haya una mayor separación entre las tres clases. No continúe con la parte (c) hasta que las tres clases muestren al menos algún grado de separación en los dos primeros vectores de scores de componentes principales.


A continuación se realiza el ajuste de componentes principales $(PCA)$, el cual intenta reducir la dimensionalidad de la base de datos, y luego se ilustran las observaciones en las primeras 2 componentes principales, la cual logra segmentar correctamente las clases. La primera componente retiene el 84.8% de la varianza total de los datos originales, mientras la segunda el 1.2%  

```{r fig.height=3,fig.width=4,fig.align="center"}
#Ajuste
res.pca <- PCA(df[,-51],graph =F)
#Gráfico
fviz_pca_ind(res.pca,
             geom.ind = "point", #mostrar puntos
             col.ind = df$clase, #clases
             palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE, #elipses
             legend.title = "Clases"
             )+ theme_gray()
```


**c)** 

Desarrolle agrupación de K-medias de las observaciones con K = 3. ¿Qué tan bien funcionan los clústeres que obtuvo con el algoritmo de K-medias comparado con las verdaderas etiquetas de clase?

Sugerencia: puede usar la función table() en R para comparar las verdaderas etiquetas de clase con las etiquetas de clase obtenidas por agrupamiento. Tener cuidado cómo se interpretan los resultados: el agrupamiento de K-medias numera los grupos arbitrariamente, por lo que no puede simplemente comprobar si las verdaderas etiquetas de clase y las etiquetas de agrupación son las mismas.


Se realiza a continuación un análisis visual para saber como se están comportando las etiquetas que resultan de la función kmeans():

```{r}
set.seed(123)
km.out =kmeans (df[,-51],3, nstart =20)
```

```{r}
grid.arrange(
            fviz_pca_ind(res.pca,
             geom.ind = c("point","text"), #mostrar puntos
             col.ind = df$clase, #clases
             palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE, #elipses
             legend.title = "Clases")+ theme_gray(),
            
            fviz_cluster(km.out, data = df[,-51]))
```

Así entonces, como el agrupamiento de K-medias numera las clases arbitrariamente, se verifican las clases a las que pertenecen los individuos y se puede notar que las etiquetas 1 y 2 están intercaladas. Luego, se realiza el siguiente procedimiento para intercarbiar dichos valores:

```{r}
km2 <- km.out$cluster
for(i in 1:length(km2)){
  if(km2[i]==1){
    km2[i]<-2
  }else if(km2[i]==2){
    km2[i]<- 1
  }else{
    next
  }}; km2
```

De esta manera, logramos obtener las siguiente matriz de confusión, donde todas las observaciones han sido clasificadas correctamente. Es decir, que la tasa de error fue cero, por lo cual se conlcuye que  logoritmo de K-medias comparado con las verdaderas etiquetas funciona correctamente.

```{r}
table(km2,df$clase)
```


**d)**

Realice agrupamiento de K-medias con K = 2. Describa sus resultados. 


En el siguiente gráfico podemos observar que realizando el agrupamiento de K-medias con K = 2, el algoritmo clasifica los datos en dos clases, para ello, en este caso unieron las 2 poblaciones más cercanas en una sola (cluster 2, azul), las cuales corresponden a la población original 1 con distribución uniforme y a la población original 3 con distribución normal.

```{r fig.height=3,fig.width=5,fig.align="center"}
set.seed(123) #semilla
km.out =kmeans (df[,-51],2, nstart =20)
fviz_cluster(km.out, data = df[,-51])
```

**e)**

Ahora realice agrupamiento de K-medias con K = 4 y describa sus resultados.


En el siguiente gráfico podemos observar que realizando el agrupamiento de K-medias con K = 4, el algoritmo clasifica los datos en cuatro clases, para ello, en este caso separó en dos la población con mayor dispersión (cluster 2 y 3) que corresponden el las verdaderas etiquetas a las poblaciones 1 y 3 respectivamente.

```{r fig.height=3,fig.width=5,fig.align="center"}
set.seed(123) #semilla
km.out =kmeans(df[,-51],4, nstart =20)
fviz_cluster(km.out, data = df[,-51])
```

**f)**

Ahora realice agrupamiento de K-medias con K = 3 en los dos primeros vectores de scores de componentes principales, en lugar de los datos en las variables originales. Es decir, realice la agrupación de K-medias en la matriz de 60 O 2, cuya primera columna es la coordenada zi1 en la primera componente principal Z1 y la segunda columna es la coordenada zi2 en la segunda componente principal Z2. Comente los resultados.


Primero se obtienen las coordenadas de las dos primeras componentes principales, de la siguiente manera:

```{r}
Z1 <- res.pca$ind$coord[,1]
Z2 <- res.pca$ind$coord[,2]
Z<- data.frame(Z1,Z2)
```

Luego, se realiza la agrupación de K-medias con K = 3 con los datos de Z

```{r fig.height=3,fig.width=5,fig.align="center"}
set.seed(123)
km.out =kmeans(Z,3, nstart =20)
fviz_cluster(km.out, data = Z)
```

Como se puede observar, realizar agrupación de K medias con las coordenadas obtenidas en las dos primeras componenetes principales se logra también una correcta clasificación de los datos originales. Cabe mencionar que tener conocimiento acerca del número de clases, lo cual favorece los resultados del análisis y que se manifestó un cambio en escala con respercto a la original.

**g)**

Con la función scale(), realice agrupamiento de K-medias con K = 3 en los datos después de escalar cada variable para tener una desviación estándar de uno. ¿Cómo se comparan estos resultados con los obtenidos? en (b)? Explique.

```{r}
set.seed(123)
sd.data=scale(df[,-51])
km.out =kmeans (sd.data,3, nstart =20)
```

```{r fig.height=3,fig.width=5,fig.align="center"}
fviz_cluster(km.out, data = sd.data)
```

En este caso, el agrupamiento de K-medias de los datos escalados, es decir con desviación estándar de uno, también logra clasificar correctamente las tres diferentes poblaciones. Es decir, con respecto a (b) donde se hizo uso de análisis de componentes principales, ambos logran clasificar correctamente los individuos de las tres diferentes distribuciones.

