---
title: ""
author: ""
date: ""
output: pdf_document
---

\begin{titlepage}
\centering
{\scshape\Huge Introducción a la Analitíca \par}
{\scshape\Huge Modulo 2 - Tarea 2 \par}
\vspace{2cm}
{\Large Por: \par}
{\Large Daniela Pico Arredondo\par}
{\Large Juan Sebastián Falcón Granada\par}
{\Large Jhonatan Smith Muñoz García\par}
{\Large Entregado a: \par}
{\Large Mauricio Mazo Lopera \par}
\vfill
\vspace{0.5cm}

```{r echo=FALSE, out.width = "300px", out.height="150px",fig.align='center'}
knitr::include_graphics("C:/Users/Usuario/Desktop/LOGO.png")

```

\vfill
\vspace{0.5cm}
{\bfseries\LARGE Universidad Nacional de Colombia \par Sede Medellín \par}
\vspace{1cm}
{\scshape\Large Facultad de ciencias \par}
\vspace{3cm}
\end{titlepage}


## PUNTO 1

La base de datos a trabajar "College" recopila informacion de un gran numero de universidades del año 1995.

```{r, warning=FALSE}
library(ISLR)
college= College
datos = na.omit(college)
names(datos)
```
La base de datos tiene un total de 777 observaciones con 18 variables.

A continuacion se presenta un breve resumen de las 18 variables:

 1) Private: Una variable tipo factor que toma dos posibles valores; "YES" y "NO" indicando si la universidad es de caracter privado.
 
 2) Apps: Numero de aplicantes postulados a la universidad
 
 3) Accept: Numero de aplicantes recibidos a la universidad
 
 4) Enroll: Numero de estudiantes nuevos matriculados
 
 5) Top10perc: Porcentaje de estudiantes por encima del 10% de la clasificacion H.S $^1$
 
 6) Top25perc: Porcentaje estudiantes por encima del 25% de la clasificacion H.S 
 
 7) F.Undergrad: Numero de estudiantes a tiempo completo de pregrado
 
 8) P.Undergradd: Numero de estudiantes a tiempo parcial de pregrado
 
 9) Outstate: Matricula fuera del estado.
 
 10) Room.Board: Costos de la habitacion y sostenimiento
 
 11) Books: Costo estimado en libros.
 
 12) Personal: Costo estimado gastos personales
 
 13) PhD: Porcentaje de profesores con Doctorados.
 
 14) Terminal: porcentaje de profesors con "terminal degree"$^2$
 
 15) S.F.Ratio: Proporcion Estudiantes/docentes
 
 16) perc.alumni: Porcentajes de ex alumnos que donan a la universidad
 
 17) Expend: gastos de educacion por estudiantes
 
 18) grad.rate: tasa de graduacion


*1* Una manera de evaluacion rendimiento academico en estados unidos. https://blog.prepscholar.com/what-is-class-rank-why-is-it-important

*2* Un terminal degree es una forma de evaluar el rendimiento en la carrera como docente. Es, generalmente otorgado por la universidad como un titulo cuando el profesional no decide comenzar su trabajo doctoral.https://en.wikipedia.org/wiki/Terminal_degree 


a) **Particione los dados en un conjunto de entrenamiento y otro de validación.**

Se procede a particionar los datos entre conjunto de entrenamiento y prueba.

Tenga presente que los metodos no utilizan variables categoricas, por tanto se elmminará la variable *Private* para aplicar los metodos PCR y PLS.

```{r, warning=FALSE,message=FALSE}
datos = na.omit(college[-1])
set.seed(1998)
proporcion = 0.7
train = sample(1:nrow(datos), size = nrow(datos)*proporcion)
test = -train
```

La idea detras de esta division es usar validacion cruzada (CV) para aplicar los siguientes metodos.

b) **Ajuste un modelo PCR considerando los datos de entrenamiento con M (número de componentes principales) seleccionado a través de validación cruzada. ¿Cuál es el error de test obtenido para el M seleccionado?**

Se busca predecir el numero de solicitues recibidas en funcion de las otras variables del conjunto de datos. Es decir:

$$Y_{i}=\theta_{0}+\theta_{1} Z_{i 1}+\theta_{2} Z_{i 2}+\cdots+\theta_{M} Z_{i M}+\epsilon_{i}$$
Donde M son el numero de componentes principales seleccionando a travez de validacion cruzada. Entonces:

```{r warning=FALSE,message=FALSE}
set.seed(1998)
require(pls)
attach(datos)
pcr.fit = pcr(Apps~., data = datos, subset= train, scale=TRUE, validation = "CV")# PCR de train
summary(pcr.fit)
```

Al observar el % de varianza explicada con los datos de entrenamiento, se observa que los componentes 7,8,9,10,11,12,14 y 14 son practicamente identicos salvo algunas diferencias muy sutiles. Por ejemplo, la diferencia entre el componente 7 y el 14 es de un porcentaje de varianza explicada de 0.69 la pregunta es, ¿esta ganancia es suficiente? ¿es mucha o poca esa ganancia? Dependiendo de la naturaleza del problema se decide, sin embargo; se opta por seleccionar en este caso la componente 7. 

Seleccionando en un principio la componente 7, se tendra que la variabza explicada para las X's es de 85.21 y para la Y es de 89.06

Para la correcta seleccion, se hace un analisis grafico:
Esta es la grafica de la raiz cuadrada de la media cuadratica del error de entrenamiento

```{r, warning=FALSE,message=FALSE}
set.seed(1998)
validationplot(pcr.fit,val.type = "RMSEP", type = "b", xlab = "# de componentes", main = "Error aplicaciones (Apps)") 
```

Segun esto, se podria concluir que el mas optimo seria aquel que suelte un error mas bajo. En este caso, seria con 15/16 componentes (son muy parecidos).

Pero entonces, no serviria de mucho pues el proceso de reduccion de dimensionalidad seria nulo. Ademas, ¿Es mucha la diferencia entre los errores entre 7 y 15/16 componentes? Esto habria que constatarlo con un experto pero en un principio, no se ve mucha diferencia. Por lo anterior se decide trabajar con 7 componentes, intentando llevar siempre un principio de parsimonia. 

```{r, warning=FALSE,message=FALSE}
X = model.matrix(Apps~., datos)[,-1]
Y = datos$Apps
y.test = Y[test]
set.seed(1998)
pcr.pred.1 = predict(pcr.fit, X[test,], ncomp = 7)
mean((pcr.pred.1-y.test)^2) # Prediccion error datos de prueba
```

Este es el error estimado con los datos de prueba. Ahora, se procede a ajustar nuevamente el modelo PCR con ayuda del M (7) hallado por CV.

```{r, warning=FALSE,message=FALSE}
pcr.fit.2 = pcr(Y~X,scale=T, ncomp = 7 )
summary(pcr.fit.2)
```

Y este seria finalmente el modelo con los datos completos, usando 7 componentes y obtener un porcentaje de varianza explicado en X de 85.03% y en Y de 84.13%

c) **Ajuste un modelo PLS considerando los datos de entrenamiento con M (número de componentes principales) seleccionado a través de validación cruzada. the training ¿Cuál es el error de test obtenido para el M seleccionado?**


```{r, warning=FALSE,message=FALSE}
set.seed(1998)
pls.fit = plsr(Apps~., data=datos, subset = train, scale =T, validation = "CV") # PCL en datos de entrenamiento
summary(pls.fit)
```

Observando lo anterior, se puede observar que, la diferencia entre los 16 componentes y solo 3 componentes es de cerca del 2%. Se recuerda que, dependiendo del contexto del problema, ese 2% de diferencia podria o no ser sustancial. Pero para efectos practicos, se supone en este caso irrelevante esa diferencia. 

Ahora, tenga presente algo; el interes del problema radica en explicar la variabilidad de "Apps", la variable problema, no de las  X's entre si. 

Con 3 componentes, la variabilidad de interes ya es explicada de manera eficiente. ¿Importa explicar la variabilidad de las X's? Bueno, dado el caso que si, entonces no se escogeria el modelo con 3 componentes, los candidatos serian entonces 10,11,12 componentes. Esto asignando una variabilidad explicada mayor al 85% en las X's.

d) **De los dos métodos anteriormente expuestos, ¿cuál muestra mejores resultados?**

```{r, warning=FALSE,message=FALSE}
set.seed(1998)
validationplot(pls.fit, val.type = "RMSEP", type = "b")
grid()
```

Segun este grafico, lo recomendable seria tomar 10 componentes.

Al analizar nuevamente los resultados anteriores se tiene que con 10 componentes el eeror obtenido es de 1018, la variabilidad de las X's es de 85.73% y de la Y es de 92.99%

Aun asi, esto no queda muy claro, debido a que entre el 8 y el 16 casi que toman valores iguales entonces al analizar los valores de los RSMEP y los porcentajes de variabilidad explicada para las componentes de las 16 se tiene que:

 a) El RSMEP se "estabiliza" a partir de 10 componentes (1016).
 
 b) El RSEMO no es muy diferente a partir de las componentes 5 en adelante. Aparenta ser "poco" dicho error. Ahora, ¿Es poco? Acorde a la naturaleza del problema y nuevamente, con ayuda de un experto, se podria dictaminar si es o no alta esa diferencia. En este caso, se opta por considerar que el RSMEP no difiere mucho a partir de 5 componentes
 
 c) Suponga que se desea tener alta interpretabilidad de la varianza para las X's y para la Y. Suponga tambien que alta interpretabilidad es a partir del 85% (podria ser 90, 95, 80, depende del contexto).
 
 d) Con lo anterior se establece que el numero optimo de componentes serán 10, como ya se habia previamente sospechado. 


Para comparar rendimiento, se procede a realizar error de prueba o test.

```{r, warning=FALSE,message=FALSE}
set.seed(1998)
pls.pred = predict(pls.fit, X[test,], ncomp = 10) # Prediccion con 10 componentes
mean((pls.pred- y.test)^2)
```
Este es el error obtenido.

```{r, warning=FALSE,message=FALSE}
pcl.fit.3 = plsr(Y~X, scale= T, ncomp = 10)
summary(pcl.fit.3)
```

Planteando el modelo con todos los datos y 10 componentes se obtiene una variabilidad de las X's de 85.35 y de la Y de un 92.77.

Note que si el interes fuese solo eplicar Y, un modelo con 3 componentes bastaria para explicar mas del 85% de variabilidad.



## PUNTO 2

a) **Cargue la base de datos en R, guardela como .RData y luego carguela nuevamente. ¿Cuál fue la reducción en tamaño del archivo?**

```{r,warning=FALSE}
library(ISLR)
library(boot)
base7<-read.table(file.choose(),header=T, sep=" ")
```


```{r,warning=FALSE}
save(base7,file="base7.rda")
```

```{r,warning=FALSE}
object.size(base7)
```


```{r,warning=FALSE}
object.size(load("base7.rda"))

```
La base de datos pesaba originalmente 223254328 bytes, la reduccion total de tamaño al guardar la base de datos como un archivo .Rdata fue de 223254216 bytes, quedando con un tamaño de tan solo 112 bytes, acortando por mucho los tiempos de carga de la base y optimizando futuros procesos.


b) **Realice un análisis para seleccionar las variables más relevantes para explicar Y.**

Se tiene una base de datos con 89717 observaciones y 311 variables

Se utilizara regresion Lasso para escoger las variables a utilizar

```{r, warning=FALSE, message=FALSE}
library(ISLR)
library(boot)
library(glmnet)
library(kableExtra)
set.seed(1000395186)
matriz<-model.matrix(Y~.,base7)
gridz<-10^seq(-2,10, lenght=100)
modlasso<-glmnet(matriz,base7$Y,alpha=1, lambda=gridz)
train<-sample(1: nrow(matriz), nrow(matriz)/2)
test<- -train
y.test<-base7$Y[test]
cv.b7<-cv.glmnet(matriz[train,],base7$Y[train],alpha=1)
bestlam<-cv.b7$lambda.min
lasso.pred<-predict(modlasso, s=bestlam,newx=matriz[test,])
out<-glmnet(matriz,base7$Y,alpha=1)
lasso.coef<-predict(out,type="coefficients",s=bestlam)[1:315,]
kable(lasso.coef[lasso.coef!=0], "latex", booktabs = T) %>%
   kable_styling(latex_options = "HOLD_position")



```

Las variables obtenidas mediante regresion Lasso son $X_{3},X_{31},X_{48},X_{99}$ y $X_{182}$, siendo $X_{99}$ una variable categorica y el resto numericas.




```{r, warning=FALSE, echo=FALSE}
v7<-data.frame(base7$X3,base7$X31,base7$X48,base7$X182)
library(kableExtra)
kable(summary(v7), "latex", booktabs = T) %>%
   kable_styling(latex_options = "HOLD_position")
kable(table(base7$X99), "latex", booktabs = T) %>%
   kable_styling(latex_options = "HOLD_position")
```

Se tiene la media de cada variable numerica junto con sus valores minimos y maximos. De igual manera se observan las 4 categorias de la variable $X_{99}$ y su respectiva frecuencia, la cual es muy cercana para los 4 niveles L1, L2, L3 y L4 

c) **Grafique las variables más relevantes versus Y y ajuste un modelo. ¿El comportamiento Y es lineal con todas las variables explicativas?**

```{r,warning=FALSE, echo=FALSE}
par(mfrow=c(2,2))
plot(base7$X3,base7$Y,pch=20,xlab="Variable X3",ylab = "Y",col="purple")
plot(base7$X31,base7$Y,pch=20,xlab="Variable X31",ylab = "Y",col="yellow")
plot(base7$X48,base7$Y,pch=20,xlab="Variable X48",ylab = "Y",col="green")
plot(base7$X182,base7$Y,pch=20,xlab="Variable X182",ylab = "Y",col="brown")
```

Se observan en las graficas de dispersion de las 4 variables numericas, que la variable $X_{3}$ tiene un comportamiento lineal sin aparente correlacion, similarmente la variable $X_{48}$ tambien tiene un comportomaiento lineal, con una aparente realacion lineal positiva. Para las variables $X_{31}$ y $X_{182}$ se observa un comportamiento no lineal creciente positivo, lo cual indica que deben ser modeladas mediante un polinomio.

```{r,warning=FALSE}
library(ggplot2)
ggplot(base7, aes(x=X99,y=Y))+
  geom_boxplot(col=c("#66CDAA","#FF8C00","#FF1493","#FFD700"))

```

En el grafico Boxplot de la variable categorica $X_{99}$ se observa que los 4 niveles tienen un rango muy similar, asi como valores muy cercanos tanto en sus cuantiales como en su valor promedio

d) **Ajuste un modelo polinómico y un modelo con funciones paso. Compare ambos modelos. ¿Cuál seleccionaría como el mejor modelo?**


```{r,warning=FALSE}

X99<-factor(base7$X99)
set.seed(1000395186)
n = nrow(base7)
trainIndex = sample(1:n, size = round(0.75*n), replace = F)
train = base7[trainIndex, c("Y","X99","X3" ,"X31", "X182", "X48")]
test = base7[-trainIndex, c("Y","X99","X3" ,"X31", "X182", "X48")]

```

Se realizo la separacion del conjunto de datos de entrenamiento con los primeros 75% y de los datos de prueba correspodientes al otro 25%. 

Como se menciono anteriormente $X_{3}$ y $X_{48}$ parecen tener un comportamiento lineal, se encontrara el mejor polinomio para las variables $X_{31}$ y $X_{182}$


```{r,warning=FALSE}
mod1_x31<-glm(Y~poly(X31, 2),data=base7)
cv.err1_x31<-cv.glm(base7, mod1_x31, K=10)
cv.err1_x31$delta[1]

mod2_x31<-glm(Y~poly(X31, 3),data=base7)
cv.err2_x31<-cv.glm(base7, mod2_x31, K=10)
cv.err2_x31$delta[1]

mod3_x31<-glm(Y~poly(X31, 4),data=base7)
cv.err3_x31<-cv.glm(base7, mod3_x31, K=10)
cv.err3_x31$delta[1]

mod4_x31<-glm(Y~poly(X31, 5),data=base7)
cv.err4_x31<-cv.glm(base7, mod4_x31, K=10)
cv.err4_x31$delta[1]

```
Ajustando 4 modelos con polinomios 2,3,4 y 5 con glm, se comparan mediante los estimadores del error de prueba con validacion cruzada k-fold cual es el mejor polinomio para la variable $X_{31}$, la cual es un polinomio de grado 4. 

Ahora para la variable $X_{182}$

```{r,warning=FALSE}
mod1_x182<-glm(Y~poly(X31, 2),data=base7)
cv.err1_x31<-cv.glm(base7, mod1_x182, K=10)
cv.err1_x31$delta[1]

mod2_x182<-glm(Y~poly(X31, 3),data=base7)
cv.err2_x31<-cv.glm(base7, mod2_x182, K=10)
cv.err2_x31$delta[1]

mod3_x182<-glm(Y~poly(X31, 4),data=base7)
cv.err3_x31<-cv.glm(base7, mod3_x182, K=10)
cv.err3_x31$delta[1]

mod4_x182<-glm(Y~poly(X31, 5),data=base7)
cv.err4_x31<-cv.glm(base7, mod4_x182, K=10)
cv.err4_x31$delta[1]
```
Para la variable $X_{182}$ el mejor polinomio resulta ser el de grado 4.


Se ajusta entonces el modelo polinomico
```{r,warning=FALSE}
mod_poly<- lm(Y ~X99+X48+X3+poly(X31,4) + poly(X182,4), data = train)
summary(mod_poly)
```
Se observa que casi todas las variables resultan ser significativas, a excepcion de los niveles L3 y L4 de la variable $X_{99}$, y el polinomio de grado 4 de la variable $X_{182}$, y la variable $X_{3}$ como tal, algo que tiene sentido pues como se observo en el grafico de dispersion, estas variables estan aparentemente incorrelacionadas. Por otro lado se observa que el $R_{adj}^2$ es igual a 0.9999, lo que indica que casi toda la variabilidad de la variable respuesta es explicada por este modelo.

Ahora se para ajustar el modelo con funciones paso, se estableceran los 4 puntos de corte para los datos de entrenamiento y de prueba.


```{r,warning=FALSE}
train$X3.cut <- cut(train$X3, breaks = 4)
train$X31.cut <- cut(train$X31, breaks = 4)
train$X48.cut <- cut(train$X48, breaks = 4)
train$X182.cut <- cut(train$X182, breaks = 4)
test$X3.cut <- cut(test$X3, breaks = 4)
test$X31.cut <- cut(test$X31, breaks = 4)
test$X48.cut <- cut(test$X48, breaks = 4)
test$X182.cut <- cut(test$X182, breaks = 4)
```

```{r,warning=FALSE}
mod_paso <- lm(Y~X99+X3.cut+X31.cut+X48.cut+X182.cut, data = train)
summary(mod_paso)
```
Se observa que nuevamente los niveles L3 y L4 de $X_{99}$ no son significativos, y 2 intervalos generados por los cortes de la variables $X_{3}$ tampoco lo son. Por otro lado el modelo explica un 87.54% de la variabilidad de Y.

Como mejor modelo seleccionamos el modelo polinomial el cual explica 

## PUNTO 3

**Usando la Función Loess ajuste un curva a los datos de la base de datos WAGE(wage en función de age)**

A continuación se muestra el comportamiento de los datos de Wage en función de age 

```{r, echo=FALSE, warning=FALSE}
library(ISLR)
names(Wage)
plot(Wage$age, Wage$wage, pch=19,
col="gray",xlab="Age", ylab="Wage")
```
Ahora se Ajusta una curva que describe el comportamiento de los datos utilizando la función Loess

```{r}
mod_loess <- suppressWarnings(loess(Wage$wage ~ Wage$age, span=0.1, data = Wage))
summary(mod_loess)
```
```{r, warning=FALSE}
library(ggplot2)
G3loess<-ggplot(Wage, aes(Wage$age, Wage$wage) ) +
  geom_point() +
  stat_smooth(method="loess")
G3loess
```


## PUNTO 4

```{r include=FALSE}
require(ISLR)
```

Considerela base de datos **Credit** del paquete **ISLR** Suponiendo que la variable de interes es **Balance**, realice la siguiente actividad:

a) **Realice gráficos que permitan ver las relaciones existentes entre todas las variables de la base de datos**

A continuacion, se realiza una breve descripcion de las variables de la base de datos:

 *ID:* Identificacion
 *Income:* Ingresos en $10.000
 *Limit:* Límite de crédito
 *Rating:* Calificacion crediticia
 *Age:* edad
 *Education:* Numeros de años de estudio
 *Cards:* Numero de tarjetas de credito
 *Gender:* Genero
 *Student:* Un factor con niveles "Si" y "no" que indica si el individuo es o no estudiante
 *Married:* Factor con niveles "Si" y "No" Que indica si el individuo está casado
 *Ethnicity:* Un factor de niveles "Afrodescendiente", "Asiatico", "caucasico" que indica la etnia del individuo. 
 *Balance:* saldo promedio de la tarjeta de credito en $

Un primer acercamiento a los datos se realiza con un analisis descriptivo de los mismos. Esto, con la intencion de en un principio, entender y ver el comportamiento de los datos dado el problema planteado (predecir acorde a la variable de interes Balance).


```{r echo=FALSE, warning=FALSE}
Credit = Credit
attach(Credit)
```

```{r echo=FALSE}
pairs(Balance~ Education+Age+Cards+Rating+Limit+Income, data = Credit, col = "skyblue")
```

Este grafico se utiliza para ver tendencia entre los datos de tipo numerico. Se observa que existe relaciones entre ciertas variables.
Por ejemplo, Limit y Rating tienen una tendencia positiva, asi como Limit e Income.

La variable respuesta Balance se relaciona de manera positiva con limit y rating.

```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width="90%", align="center"}
par(mfrow=c(3,3), cex=0.6)
boxplot(Income~Gender, main = "Gender vs Income")
boxplot(Limit~Gender, main = "Gender vs Limit")
boxplot(Rating~Gender, main = "Gender vs Rating")
boxplot(Cards~Gender, main = "Gender vs Cards")
boxplot(Age~Gender, main = "Gender vs Age")
boxplot(Education~Gender, main = "Gender vs Education")
boxplot(Balance~Gender, main = "Gender vs Balance")
boxplot(Income~Student, main = "Student vs Income")
boxplot(Limit~Student, main = "Student vs Limit")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width="90%"}
par(mfrow=c(3,3), cex=0.6)
boxplot(Rating~Student, main = "Student vs Rating")
boxplot(Cards~Student, main = "Student vs Cards")
boxplot(Age~Student, main = "Student vs Age")
boxplot(Education~Student, main = "Education vs Student")
boxplot(Balance~Student, main = "Balance vs Student")
boxplot(Income~Married, main = "Married vs Income")
boxplot(Limit~Married, main = "Married vs Limit")
boxplot(Rating~Married, main = "Married vs Rating")
boxplot(Cards~Married, main = "Married vs Cards")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width="90%"}
par(mfrow=c(2,3), cex=0.6)
boxplot(Age~Married, main = "Married vs Age")
boxplot(Education~Married, main = "Married vs Education")
boxplot(Balance~Married, main = "Married vs Balance")
boxplot(Income~Ethnicity, main = "Ethnicity vs Income")
boxplot(Limit~Ethnicity, main = "Ethnicity vs Limit")
boxplot(Rating~Ethnicity, main = "Ethnicity vs Rating")
```


```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
par(mfrow=c(2,2))
boxplot(Cards~Ethnicity, main = "Ethnicity vs Cards")
boxplot(Age~Ethnicity, main = "Ethnicity vs Age")
boxplot(Education~Ethnicity, main = "Ethnicity vs Education")
boxplot(Balance~Ethnicity, main = "Ethnicity vs Balance")

```


El anterior es un analisis descriptivo de las variables categoricas vs continuas. En general no se observan diferencias por categorias exceptuando *Student vs Balance* donde las personas que fueron estudiantes en promedio, tenian un saldo de tarjetas mas altos.  

 b) **Seleccione un conjunto de variables que considere útiles para modelar Balance**
 
Considerando lo anterior, lo ideal es seleccionar y analzar variables que ayuden a explicar Balance si, de alguna manera, se encuentran relacionadas con la misma. 

Dado en analisis anterior se decide tomar el conjunto de variables Income, Limit, Student y Rating para modelar a Balance. Esto dado que se observa una relacion entre las variables mencionadas y la variable objetivo. Los otros no se observa relacion apreciable mas allá de una nube de puntos aleatoria (carencia de relacion)

c) **Por medio de un analisis de varianza de modelos anidados, plantee al menos 4 modelos GAM**

Se ajustan los modelos GAM anidados de la siguiente manera.

```{r message=FALSE, warning=FALSE}
require(gam)

modelo.gam.1 <- gam(Balance~Limit+Rating, data = Credit)
modelo.gam.2 <- gam(Balance~Limit+Rating+Student, data = Credit)
modelo.gam.3 <- gam(Balance~Limit+Rating+Student+Income, data = Credit)
modelo.gam.4 <- gam(Balance~Limit+Rating+Student+s(Income, df = 3), data = Credit)

anova(modelo.gam.1,modelo.gam.2,modelo.gam.3,modelo.gam.4, test = "F")
```

Se observa que el p-value de los modelos 2 y 3 es pequeño. Esto se traduce en que las variables Income y Student son de importancia para explicar el comportamiento de Balance. Sin embargo, esto complica la variable Income con dos nodos ya que no hay un aporte significativo para el modelo. En general, aplicar un modelo con n nodos (n>0) complica el modelo y no hay una ganancia significativa. 


d) **Usando CV, seleccione el mejor modelo entre los cuatro modelos planteados en el item anterior**

La seleccion del modelo para explicar Balance (Saldo en Tarjeta de Credito), se procede a realizar validacion cruzada (CV) con la base de datos, dividiendo un 70% para entrenamiento y un 30% para prueba.

```{r, message=FALSE, warning=FALSE}
set.seed(1998)

prop = 0.7
t1 = sample(length(Credit$Balance), size = (length(Credit$Balance)*prop))

train = Credit[t1,]
test <- Credit[-t1,]
y = train$Balance
y1 <- test$Balance
```


Esta es la forma en que se seleccionan las bases de datos para ajustar cada uno de los modelos anterior mente seleccionados. Se procede a analizar el MSE de los modelos y dado este criterio se decide cual modelo es el más optimo a trabajar.

```{r}

modelo.gam.1.t <- gam(Balance~Limit+Rating, data = train)
modelo.gam.2.t <- gam(Balance~Limit+Rating+Student, data = train)
modelo.gam.3.t <- gam(Balance~Limit+Rating+Student+Income, data = train)
modelo.gam.4.t <- gam(Balance~Limit+Rating+Student+s(Income, df = 3), data = train)

```

Note algo. Se parte del modelo mas sencillo, hasta un modelo mas complejo. Se procede a realizar un analisis de varianza con la tabla ANOVA de los datos de entrenamiento. 

```{r}
anova(modelo.gam.1.t, modelo.gam.2.t, modelo.gam.3.t,modelo.gam.4.t, test = "F")
```

Note que el modelo 4, que utiliza un spline (complicando el proceso) no tuvo un efecto significativo. Por este motivo, el modelo 4 es descartado. 

Ahora, el modelo 2 y 3 son significativos, lo que indica que el agregar las variables (partiendo del modelo 1) y llegar hasta el modelo 3, es el modelo que mejor explica la proporcion de varianza. Surje una pregunta. ¿Que variable tiene papel preponderante para el modelo?

```{r echo=FALSE}
a=summary(modelo.gam.3.t)
a$parametric.anova
```

En general, la variable que mayor proporcion de varianza explica de Balance es Limit. Esto se cumple para todos los otros modelos. Esto indica que Limit es una variable que si o si, debe de ir en cualquier modelo que sea seleccionado. Todas las variables son significativas. 

Se procede a analizar el AIC de cada modelo. 

```{r echo=FALSE, warning=FALSE, message=FALSE}
require(magrittr)
require(kableExtra)
```

```{r}
gam1<-modelo.gam.1.t$aic
gam2<-modelo.gam.2.t$aic
gam3<-modelo.gam.3.t$aic
gam4<-modelo.gam.4.t$aic

tabla = cbind(c(gam1,gam1, gam3, gam4))
colnames(tabla) = c("AIC")
rownames(tabla )=c("modelo 1", "modelo 2", "modelo 3", "modelo 4") 
kable(tabla, "latex", booktabs = T) %>%
   kable_styling(latex_options = "HOLD_position")
```

Por criterio de AIC, se escoje el modelo 3 nuevamente. Si bien, no es el que tiene el valor minimo, su diferencia es infima respecto a la ganancia obtenida vs la complejidad del mejor (modelo 4) por tal motivo, se escoje nuevamente el modelo 3. Ahora, se procede a comparar los MSE de todos los modelos entre si con los datos de prueba. 


```{r}

mse1 <- mean((y1- predict(modelo.gam.1.t, test))^2)
mse2 <- mean((y1- predict(modelo.gam.2.t, test))^2)
mse3 <- mean((y1- predict(modelo.gam.3.t, test))^2)
mse4 <- mean((y1- predict(modelo.gam.4.t, test))^2)

tabla1 = cbind(c(mse1, mse2,mse3,mse4))
colnames(tabla1) = c("MSE")
rownames(tabla1)=c("modelo 1 ", "modelo 2 ", "modelo 3 ", "modelo 4 ") 
kable(tabla1, "latex", booktabs = T) %>%
   kable_styling(latex_options = "HOLD_position")
```
El modelo con un menor MSE es el modelo 4. Sin embargo, la ganancia no es mucha respecto al modelo 3 dado que utiliza splines en el proceso. Finalmente, el modelo mas optimo dado el principio de parsimonia y, dado el criterio del MSE (No necesariamente el menor) y AIC, el modelo a seleccionar es el modelo que predice Balance con las variables Limit, Rating, Student e Income.

## PUNTO 5

```{r setup, include=FALSE, ,warning=FALSE}
library(ISLR)
library(boot)
base10a<-read.table(file.choose(),header=T, sep=" ")
base10b<-read.table(file.choose(),header=T, sep=" ")
```


## 5.A
Considere la base de datos DATOS_A.

a) **Seleccione las variables más importantes entre $X_{1}$, $X_{2}$, . . . , $X_{14}$ para explicar Y.**

Se tiene una base de datos con 1767 observaciones y 15 variables

Para seleccionar las variables para explicar a Y, se utilizara regresion Lasso.

```{r, warning=FALSE}
library(ISLR)
library(boot)
library(glmnet)
library(kableExtra)
set.seed(123)
matriz<-model.matrix(Y~.,base10a)
gridz<-10^seq(-2,10, lenght=100)
modlasso<-glmnet(matriz,base10a$Y,alpha=1, lambda=gridz)
train<-sample(1: nrow(matriz), nrow(matriz)/2)
test<- -train
y.test<-base10a$Y[test]
cv.b10a<-cv.glmnet(matriz[train,],base10a$Y[train],alpha=1)
bestlam<-cv.b10a$lambda.min
lasso.pred<-predict(modlasso, s=bestlam,newx=matriz[test,])
out<-glmnet(matriz,base10a$Y,alpha=1)
lasso.coef<-predict(out,type="coefficients",s=bestlam)[1:16,]
kable(lasso.coef[lasso.coef!=0], "latex", booktabs = T) %>%
   kable_styling(latex_options = "HOLD_position")

```

Las variables seleccionadas por regresion Lasso que se usaran para explicar a Y son: $X_{1}$, $X_{2}$, $X_{3}$, $X_{4}$, $X_{6}$, $X_{8}$, $X_{10}$ y $X_{14}$


b) **Realice gráficos descriptivos con las variables seleccionadas en el item anterior.**

```{r,warning=FALSE}
pairs(Y ~ X1 + X2 + X3 + X4 + X6 + X8 + X10 + X14, data = base10a, col = "skyblue")
```

Se puede observar en el grafico de diagramas de dispersion una aparente relacion lineal positiva entre la Y y la variable $X_{10}$, de igual manera se observa una relacion lineal negativa entre Y y $X_{6}$, el resto de variables parecen no tener estar linealmente relacionadas con la varible Y.

```{r, echo=FALSE,message=FALSE,figures-side, fig.show="hold", out.width="50%"}
plot(Y~X6, main="Y vs X6", data = base10a, col="orange")
plot(Y~X10,main="Y vs X10", data = base10a, col="deeppink")
```

Se observan ambos graficos de dispersion con mas claridad, evidenciadose la relacion lineal de ambas covariables con Y. 

```{r,warning=FALSE, echo=FALSE}
par(mfrow=c(2,4))
hist(base10a$X1, main = "Histograma X1",
     xlab="X1", ylab = "Frecuencia", col = "deepskyblue")
hist(base10a$X2, main = "Histograma X2",
     xlab="X2", ylab = "Frecuencia", col = "brown")
hist(base10a$X3, main = "Histograma X3",
     xlab="X3", ylab = "Frecuencia", col = "pink")
hist(base10a$X4, main = "Histograma X4",
     xlab="X4", ylab = "Frecuencia", col = "#FFD39B")
hist(base10a$X6, main = "Histograma X6",
     xlab="X6", ylab = "Frecuencia", col = "#76EE00")
hist(base10a$X8, main = "Histograma X8",
     xlab="X8", ylab = "Frecuencia", col = "#9932CC")
hist(base10a$X10, main = "Histograma X10",
     xlab="X10", ylab = "Frecuencia", col = "#008B00")
hist(base10a$X14, main = "Histograma X14",
     xlab="X14", ylab = "Frecuencia", col = "#3A5FCD")

```

En los anteriores histogramas de las covariables seleccionadas se observa que todas siguen una distribucion muy similar, con una frecuencia casi simetrica atravez del rango de observaciones. Ninguna de las variables distribuye de forma normal.

```{r,warning=FALSE, echo=FALSE, out.width="80%"}
boxplot(base10a$X1, base10a$X2,  base10a$X3, base10a$X4, base10a$X6, base10a$X8, base10a$X10, base10a$X14, main="BoxPlot Variables", xlab="Variables Explicativas", ylab="Frecuencia", col=c("deepskyblue", "brown", "pink", "#FFD39B", "#76EE00", "#9932CC",  "#008B00", "#3A5FCD"))
```

En los graficos boxplot se observa que casi todas las cajas se traslapan, e excepcion de la variable $X_{10}$ que tiene un rango muy grande a comparacion del resto y alcanza los valores mas elevados. Por otro lado la variable $X_{1}$ tiene el rango mas acortado y tampoco se traslapa con el resto de cajas. 

c) **Ajuste al menos 3 modelos GAMLSS donde considere distintas funciones de suavizamiento, además de un ajuste para la variabilidad.**

Se ajustaran 3 modelos GAMLSS, primero observaremos que distribucion aproximada sigue la variable Y.

```{r,warning=FALSE, echo=FALSE, out.width="80%"}
hist(base10a$Y, main = "Histograma Y",
     xlab="Y", ylab = "Frecuencia", col = "#3A5FCD")
```

Segun el histograma anterior Y pareciera seguir una distribucion normal, por ello se modelaran los 3 modelos GAMLSS mediante la familia normal. Se ajustara su variabilidad mediante las variables explicativas escogidas por regresion Lasso. 

El primer modelo sera ajustado sin funcion de suavizamiento
```{r,warning=FALSE, message=FALSE}
library(gamlss)
mod1 <- gamlss(Y~X1+X2+X3+X4+X6+X8+X10+X14, sigma.fo=~X1+X2+X3+X4+X6+X8+X10+X14, family=NO(mu.link = "identity",sigma.link="log"), data=base10a)

summary(mod1)
```


El segundo modelo sera suavizado mediante splines cubicos
```{r,warning=FALSE, message=FALSE}
library(gamlss)
mod2cs <- gamlss(formula=Y~cs(X1)+cs(X2)+cs(X3)+cs(X4)+cs(X6)+cs(X8)+cs(X10)+cs(X14),
sigma.fo=~X1+X2+X3+X4+X6+X8+X10+X14,
data=base10a, family=NO(mu.link = "identity",
sigma.link="log"))
summary(mod2cs)
```


El tercer modelo sera suavizado mediante P spline 
```{r,warning=FALSE, message=FALSE}
library(gamlss)
mod3pb <- gamlss(formula=Y~pb(X1)+pb(X2)+pb(X3)+pb(X4)+pb(X6)+pb(X8)+pb(X10)+pb(X14),
sigma.fo=~X1+X2+X3+X4+X6+X8+X10+X14,
data=base10a, family=NO(mu.link = "identity",
sigma.link="log"))
summary(mod3pb)
```

d) **Seleccione el mejor modelo entre los 3 anteriores.**


\begin{table}[]
\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
    & Mod1     & Mod2     & Mod3     \\ \hline
AIC & 12491.08 & 11870.98 & 11412.09 \\ \hline
BIC & 12589.67 & 12101.03 & 11652.78 \\ \hline
\end{tabular}
\end{center}
\end{table}


Por criterio de AIC y BIC, el mejor modelo es el moodelo 3 suavizado con P splines, pues es el que tiene menores medidas.

Ahora utilizando Cross Validation para encontrar el MSE de los modelos, separamos los datos en un conjunto de entrenamiento y otro de prueba.

```{r,warning=FALSE}
set.seed(1000395186)
n <- nrow(base10a)
muestra <- sample(1:n, size = 0.75*n)
train <- base10a[muestra,]
test <- base10a[-muestra,]
y.train <- train$Y
y.test <- test$Y
```

```{r}
mse1 <- mean((y.test-predict(mod1, newdata=test))^2)
mse2 <- mean((y.test-predict(mod2cs, newdata=test))^2)
mse3 <- mean((y.test-predict(mod3pb, newdata=test))^2)
mse1
mse2
mse3
```


\begin{table}[]
\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
    & Mod1     & Mod2     & Mo3      \\ \hline
MSE & 73.13783 & 48.53057 & 38.33667 \\ \hline
\end{tabular}
\end{center}
\end{table}


Por criterio del MSE el mejor modelo es nuevamente el modelo 3 con P spline, por ende se concluye que este es el mejor de los 3

## 5.B

La base de datos DATOS_B contiene registros de accidentalidad de 728 días en una de las avenidas principales de cierta
ciudad.

a) **Ajuste un modelo gamlss a los datos considerando la distribución Poisson.**

```{r,warning=FALSE, message=FALSE}
library(gamlss)
mod_poi <- gamlss(formula=Y~X1+X2+X3,
family = PO(mu.link = "log"),
data = base10b)

summary(mod_poi)
```

b) **Interprete el modelo ajustado**

El modelo busca explicar el numero de accidentes diarios, la interpretacion de los parametros del modelo es la siguiente: 

Intercepto: Se interpreta que el numero de accidentes de trafico disminuira en un  0.3779 siempre y cuando todas las demas variables sean cero. 

$X_{1}$: Se interpreta como que el numero de accidentes de trafico aumentaran en 0.0003093 por cada vehiculo que transite ese dia particular, es decir, al transitar 1000 vehciulos, el numero de accidentes de trafico sera de aproximadamente 3, cuando las demas variables son cero.

$X_{2}$: Se interpreta como que cuando es un dia lluvioso, los accidentes de transito aumentaran en 0.01276, pues cuando no llueve esta variable contribuye cero al aumento de accidentes.

$X_{3}$: Se interpreta como el numero de accidentes que se esperan dependiendo del dia de la semana, siendo todos valores positivos bastante cercanos, con el dia miercoles como el mas alto, y la ausencia del domingo que indica una contribucion nula y por ende el dia con menos accidentes de transito.

c) **Escriba la ecuación del modelo.**


$$\widehat{Y_{i}}=3.779e^{-1}+3.093e^{-4}X_{1}+1.276e^{-2}X_{2}+ 3.956e^{-1}X_{LUN}+3.937e^{-1}X_{MAR}+
3.969e^{-1}X_{MIE}+3.899e^{-1}X_{JUE}$$ $$+3.923e^{-1}_{VIE}+
3.110e^{-1}X_{SAB}$$



