MSE.Prueba <- cv.knn(Predictoras = Pred, Respuesta = Resp, Kmax = 30, K = 10)
names(MSE.Prueba) <- 1:30
V <- MSE.Prueba == min(MSE.Prueba)
MSE.Prueba[V]
which.min(MSE.Prueba)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
normalize <- function(x) {
norm <- ((x - min(x))/(max(x) - min(x)))
return (norm)
}
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- as.vector(test["Direction"])
fit.knn_train <- class::knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=6, prob=TRUE)
fit.knn_Test<-class::knn(train=train_norm, test = test_norm ,cl= y_train$Direction, k=6, prob=TRUE)
#matriz de confusión
Predicted_test<-factor(fit.knn_Test)
t1<-table(Predicted_test,y_test$Direction)
t1
fit.knn_Test<-class::knn(train=train_norm, test = test_norm ,cl= y_train$Direction, k=6, prob=TRUE)
#matriz de confusión
Predicted_test<-factor(fit.knn_Test)
t1<-table(Predicted_test,y_test$Direction)
t1
plot(MSE.Prueba, type = "b")
#matriz de confusión
glm.pred <- predict(mod_glm, test[,-4], type="response")
train <- (df$Year<2019)
datos<- read.csv("HPQ.csv")
datos$Date <- as.Date(datos$Date, format = "%Y-%m-%d")
library(kableExtra)
head(datos, 3) %>% kbl() %>% kable_styling()
Year <- substr(datos$Date, 1,4) #extraer anio
Year <- as.numeric(Year)
Today <- datos$Close - datos$Open #Calcular rendimiento
Direction <- ifelse(Today < 0, "down", "up")
Direction <- as.factor(Direction)
df <- data.frame(Year, "Volume"= datos$Volume, Today, Direction)
library(Hmisc)
df$lag1 <- Lag(df$Today, 1)
df$lag2 <- Lag(df$Today, 2)
df$lag3 <- Lag(df$Today, 3)
df$lag4 <- Lag(df$Today, 4)
df$lag5 <- Lag(df$Today, 5)
df <- df[-c(1:5),]
head(df)%>% kbl() %>% kable_styling()
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
#matriz de confusión
glm.pred <- predict(mod_glm, test[,-4], type="response")
#matriz de confusión
glm.pred <- predict(mod_glm, test[,-4], type="response")
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
mod_glm <- glm(Direction ~ lag1+lag2+lag3+lag4+lag5+Volume, data = df, family = binomial, subset = train)
#matriz de confusión
glm.pred <- predict(mod_glm, test[,-4], type="response")
glm.pred <- ifelse(glm.pred < 0.53, "down", "up")
t<-table(glm.pred, test$Direction);t
sum(diag(t))/sum (t)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
normalize <- function(x) {
norm <- ((x - min(x))/(max(x) - min(x)))
return (norm)
}
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- as.vector(test["Direction"])
fit.knn_train <- class::knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=6, prob=TRUE)
fit.knn_Test<-class::knn(train=train_norm, test = test_norm ,cl= y_train$Direction, k=6, prob=TRUE)
#matriz de confusión
Predicted_test<-factor(fit.knn_Test)
t1<-table(Predicted_test,y_test$Direction)
t1
sum(diag(t1))/sum(t1)
#matriz de confusión
Pred.lda<-predict(mod_lda , test)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
mod_lda <- MASS::lda(Direction~lag1+lag2+lag3+lag4+lag5+Volume,data = df, subset = train)
mod_lda
#matriz de confusión
Pred.lda<-predict(mod_lda , test)
Clase.lda = Pred.lda$class
t<-table(Clase.lda,test$Direction);t
sum(diag(t))/sum(t)
#matriz de confusión
Pred.qda<-predict(mod_qda , test)
mod_qda <- MASS::qda(Direction~lag1+lag2+lag3+lag4+lag5+Volume, data = df, subset = train)
mod_qda
#matriz de confusión
Pred.qda<-predict(mod_qda , test)
Clase.qda =Pred.qda$class
t1<-table(Clase.qda, test$Direction);t1
sum(diag(t1))/sum(t1)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
setwd("~/Downloads/Analitica/Analitica-mod2")
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
tasa_error<-vector()
for (i in 1:10){
knn.train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=6,prob=T)
knn.test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=6, prob=T)
Pred_test <-factor(knn_test$pred)
tasa_error[i]<- sum(pred_test == test$Direction)/ nrow(test)
}
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
tasa_error<-vector()
for (i in 1:10){
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=6,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=6, prob=T)
Pred_test <-factor(knn_test$pred)
tasa_error[i]<- sum(pred_test == test$Direction)/ nrow(test)
}
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- as.vector(test["Direction"])
tasa_error<-vector()
for (i in 1:10){
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=6,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=6, prob=T)
Pred_test <-factor(knn_test$pred)
tasa_error[i]<- sum(pred_test == test$Direction)/ nrow(test)
}
y_train
y_train$Direction
knn_test
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
normalize <- function(x) {
norm <- ((x - min(x))/(max(x) - min(x)))
return (norm)
}
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- as.vector(test["Direction"])
fit.knn_train <- class::knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=6, prob=TRUE)
fit.knn_Test<-class::knn(train=train_norm, test = test_norm ,cl= y_train$Direction, k=6, prob=TRUE)
#matriz de confusión
Predicted_test<-factor(fit.knn_Test)
t1<-table(Predicted_test,y_test$Direction)
t1
fit.knn_Test
factor(fit.knn_Test)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- as.vector(test["Direction"])
tasa_error<-vector()
for (i in 1:10){
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=6,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=6, prob=T)
Pred_test <- factor(knn_test)
tasa_error[i]<- sum(pred_test == y_test)/ nrow(y_test)
}
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- as.vector(test["Direction"])
tasa_error<-vector()
for (i in 1:10){
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=6,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=6, prob=T)
pred_test <- factor(knn_test)
tasa_error[i]<- sum(pred_test == y_test)/ nrow(y_test)
}
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- factor(test["Direction"])
tasa_error<-vector()
for (i in 1:10){
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=i,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=i, prob=T)
pred_test <- factor(knn_test)
tasa_error[i]<- sum(pred_test == y_test)/ nrow(y_test)
}
nrow(knn_test)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- factor(test["Direction"])
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=1,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=1, prob=T)
pred_test <- factor(knn_test)
sum(pred_test == y_test)/ nrow(y_test)
y_test
test["Direction"]
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- test["Direction"]
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=1,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=1, prob=T)
pred_test <- factor(knn_test)
sum(pred_test == y_test)/ nrow(y_test)
y_test
pred_test
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- test["Direction"]
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=1,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=1, prob=T)
pred_test <- factor(knn_test)
sum(pred_test == y_test$Direction)/ nrow(y_test)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- test["Direction"]
tasa_error<-vector()
for (i in 1:10){
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=i,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=i, prob=T)
pred_test <- factor(knn_test)
tasa_error[i] <- sum(pred_test == y_test$Direction)/ nrow(y_test)
}
plot(1:10,tasa_error, xlab="k", ylab="tasa de error",type="b",col=4)
tasa_error
plot(1:10,tasa_error, xlab="k", ylab="tasa de error",type="b",col=4)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- test["Direction"]
tasa_error<-vector()
for (i in 1:10){
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=i,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=i, prob=T)
pred_test <- factor(knn_test)
tasa_error[i] <- sum(pred_test != y_test$Direction)/ nrow(y_test)
}
plot(1:10,tasa_error, xlab="k", ylab="tasa de error",type="b",col=4)
plot(1:10,tasa_error, xlab="k", ylab="tasa de error",type="b",col=4)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- test["Direction"]
tasa_error<-vector()
for (i in 1:30){
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=i,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=i, prob=T)
pred_test <- factor(knn_test)
tasa_error[i] <- sum(pred_test != y_test$Direction)/ nrow(y_test)
}
plot(1:30,tasa_error, xlab="k", ylab="tasa de error",type="b",col=4)
plot(1:30,tasa_error, xlab="k", ylab="tasa de error",type="b",col=4)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- test["Direction"]
tasa_acierto<-vector()
for (i in 1:20){
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=i,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=i, prob=T)
pred_test <- factor(knn_test)
tasa_acierto[i] <- sum(pred_test == y_test$Direction)/ nrow(y_test)
}
plot(1:20,tasa_acierto, xlab="k", ylab="tasa de error",type="b",col=4)
plot(1:20,tasa_acierto, xlab="k", ylab="tasa de error",type="b",col=4)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- test["Direction"]
tasa_acierto<-vector()
for (i in 1:20){
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=i,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=i, prob=T)
pred_test <- factor(knn_test)
tasa_acierto[i] <- sum(pred_test == y_test$Direction)/ nrow(y_test)
}
plot(1:20,tasa_acierto, xlab="k", ylab="tasa de acierto",type="b",col=4)
max(tasa_acierto)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- test["Direction"]
tasa_acierto<-vector()
for (i in 1:20){
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=i,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=i, prob=T)
pred_test <- factor(knn_test)
tasa_acierto[i] <- sum(pred_test == y_test$Direction)/ nrow(y_test)
}
plot(1:20,tasa_acierto, xlab="k", ylab="tasa de acierto",type="b",col=4)
which.max(tasa_acierto)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
normalize <- function(x) {
norm <- ((x - min(x))/(max(x) - min(x)))
return (norm)
}
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- as.vector(test["Direction"])
fit.knn_train <- class::knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=10, prob=TRUE)
fit.knn_Test<-class::knn(train=train_norm, test = test_norm ,cl= y_train$Direction, k=10, prob=TRUE)
#matriz de confusión
Predicted_test<-factor(fit.knn_Test)
t1<-table(Predicted_test,y_test$Direction)
t1
sum(diag(t1))/sum(t1)
mod_glm <- glm(Direction ~ lag1+lag2+lag3+lag4+lag5+Volume, data = df, family = binomial)
cv.err <-cv.glm(Auto ,mod_glm)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
mod_glm <- glm(Direction ~ lag1+lag2+lag3+lag4+lag5+Volume, data = df, family = binomial)
cv.err <-cv.glm(Auto ,mod_glm)
require(boot) # Librería con LOOCV incorporado
mod_glm <- glm(Direction ~ lag1+lag2+lag3+lag4+lag5+Volume, data = df, family = binomial)
cv.err <-cv.glm(Auto,mod_glm)
mod_glm <- glm(Direction ~ lag1+lag2+lag3+lag4+lag5+Volume, data = df, family = binomial)
cv.err <-cv.glm(df ,mod_glm)
names(cv.err)
cv.err$delta
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- test["Direction"]
tasa_acierto<-vector()
for (i in 1:20){
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=i,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=i, prob=T)
pred_test <- factor(knn_test)
tasa_acierto[i] <- sum(pred_test == y_test$Direction)/ nrow(y_test)
}
ggplot()+geom_point(data=df, aes(1:20, tasa_acierto),color="blue", size=2)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- test["Direction"]
tasa_acierto<-vector()
for (i in 1:20){
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=i,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=i, prob=T)
pred_test <- factor(knn_test)
tasa_acierto[i] <- sum(pred_test == y_test$Direction)/ nrow(y_test)
}
plot(1:20,tasa_acierto, xlab="k", ylab="tasa de acierto",type="b",col=4)
which.max(tasa_acierto)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
normalize <- function(x) {
norm <- ((x - min(x))/(max(x) - min(x)))
return (norm)
}
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- as.vector(test["Direction"])
fit.knn_train <- class::knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=6, prob=TRUE)
fit.knn_Test<-class::knn(train=train_norm, test = test_norm ,cl= y_train$Direction, k=6, prob=TRUE)
#matriz de confusión
Predicted_test<-factor(fit.knn_Test)
t1<-table(Predicted_test,y_test$Direction)
t1
sum(diag(t1))/sum(t1)
train <- (df$Year<2019)
test <- df[!train,] # Datos de test
train <- df[train,] # Datos de train
train_norm <- normalize(train[,-4])
test_norm <- normalize(test[,-4])
y_train <- train["Direction"]
y_test <- test["Direction"]
tasa_acierto<-vector()
for (i in 1:20){
knn_train <- knn(train=train_norm, test= train_norm, cl = y_train$Direction, k=i,prob=T)
knn_test <- knn(train=train_norm, test = test_norm, cl= y_train$Direction, k=i, prob=T)
pred_test <- factor(knn_test)
tasa_acierto[i] <- sum(pred_test == y_test$Direction)/ nrow(y_test)
}
plot(1:20,tasa_acierto, xlab="k", ylab="tasa de acierto",type="b",col=4)
which.max(tasa_acierto)
which.min(tasa_acierto)
pnorm(q= 3.914)
pnorm(q= 3.914,lower.tail = F)
2*pnorm(q= 3.914,lower.tail = F)
scan()
a<-scan(0.7
1.0
2.0
1.4
0.5
0.8
1.0
1.1
1.9
1.2
1.5)
a<- scan(0.7
1.0
2.0
1.4
0.5
0.8
1.0
1.1
1.9
1.2
1.5)
a<- scan()
a
a<- scan()
a
mean(a)
b<- scan()
c<- scan()
mean(a,b,c)
mean(c(a,b,c))
mean(a)
mean(b)
mean(c)
abc<- c(a,b,c)
sort(abc)
u1<- a-mean(a)
u2<- b-mean(b)
u3<- c-mean(c)
u123<- c(u1,u2,u3)
sort(abc)
u1<- abs(a-mean(a))
u1
u1<- round(abs(a-mean(a)),digits = 1)
u1
u1<- round(abs(a-mean(a)),digits = 1)
u2<- round(abs(b-mean(b)),digits = 1)
u3<- round(abs(c-mean(c)),digits = 1)
u123<- c(u1,u2,u3)
sort(abc)
u1
u2
u3
u3<- round(abs(c-mean(c)),digits = 2)
u3
mean(a)
mean(c)
c
c[11]<- 2.5
c
u1<- round(abs(a-mean(a)),digits = 1)
u2<- round(abs(b-mean(b)),digits = 1)
u3<- round(abs(c-mean(c)),digits = 2)
u3
u3<- round(abs(c-mean(c)),digits = 1)
a<- scan()
u3
u123<- c(u1,u2,u3)
sort(abc)
sort(u123)
library(nparametric)
compvar(u1,u2,test="superior")
compvar(u1,u2,u3,test="superior")
