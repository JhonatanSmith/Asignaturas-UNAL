asignacion = wh*tamaño_n
asignacion
Nh = c(86,72,52,30)
nh = c(14,12,9,5)
N = sum(Nh)
n = sum(nh)
estrato_1 = c(97,42,25,105,27,45,53,67,125,92,86,43,59,21)
estrato_2 = c(125,67,256,310,220,142,155,96,47,236,352,190)
estrato_3 = c(142,310,495,320,196,256,440,510,396)
estrato_4 = c(167,220,780,655,540)
y_h = c(mean(estrato_1),mean(estrato_2),mean(estrato_3),mean(estrato_4)) #Será el promedio en cada estrato
y_bar_est = sum((Nh/N)*y_h)
y_bar_est
t_est= sum(N*y_bar_est)
t_est
s2h = c(var(estrato_1),var(estrato_2),var(estrato_3),var(estrato_4)) #varianza
sh = sqrt(s2h)
var_yh_bar= (1-nh/Nh)*s2h/nh #Varianza de Y-Barra para cada estrato
var_y_est = 1/N^2*sum(Nh^2*var_yh_bar) # Varianza media estratificada
var_y_est
Z = qnorm(0.975)
var_t_est = sum(Nh^2*var_yh_bar)
var_t_est
B =  2*sqrt(var_t_est)
B
Z = qnorm(0.975)
var_t_est = sum(Nh^2*var_yh_bar)
var_t_est
B =  2*sqrt(var_t_est)
B
B= 5000 #Limite del error  B = 2*raiz varianza=5000
Z = 2 #qnorm(0.975)
wh_optima_costo_igual = (Nh*sh)/(sum(Nh*sh)) #Neyman
wh = wh_optima_costo_igual #Aqui va la afijacion de la muestra
D = 2500 # D es igual a la varianza de ybar o tmbien B^2/Z^2
tamaño_n = sum(((Nh^2*s2h)/wh))/(N^2*D+sum(Nh*s2h))
tamaño_n
asignacion = wh*tamaño_n
asignacion
B= 5000 #Limite del error  B = 2*raiz varianza=5000
Z = 2 #qnorm(0.975)
wh_optima_costo_igual = (Nh*sh)/(sum(Nh*sh)) #Neyman
wh = wh_optima_costo_igual #Aqui va la afijacion de la muestra
D = 25 # D es igual a la varianza de ybar o tmbien B^2/Z^2
tamaño_n = sum(((Nh^2*s2h)/wh))/(N^2*D+sum(Nh*s2h))
tamaño_n
asignacion = wh*tamaño_n
asignacion
B= 5000 #Limite del error  B = 2*raiz varianza=5000
Z = 2 #qnorm(0.975)
wh_optima_costo_igual = (Nh*sh)/(sum(Nh*sh)) #Neyman
wh = wh_optima_costo_igual #Aqui va la afijacion de la muestra
D = 50 # D es igual a la varianza de ybar o tmbien B^2/Z^2
tamaño_n = sum(((Nh^2*s2h)/wh))/(N^2*D+sum(Nh*s2h))
tamaño_n
asignacion = wh*tamaño_n
asignacion
B= 5000 #Limite del error  B = 2*raiz varianza=5000
Z = 2 #qnorm(0.975)
wh_optima_costo_igual = (Nh*sh)/(sum(Nh*sh)) #Neyman
wh = wh_optima_costo_igual #Aqui va la afijacion de la muestra
D = 100 # D es igual a la varianza de ybar o tmbien B^2/Z^2
tamaño_n = sum(((Nh^2*s2h)/wh))/(N^2*D+sum(Nh*s2h))
tamaño_n
asignacion = wh*tamaño_n
asignacion
B= 5000 #Limite del error  B = 2*raiz varianza=5000
Z = 2 #qnorm(0.975)
wh_optima_costo_igual = (Nh*sh)/(sum(Nh*sh)) #Neyman
wh = wh_optima_costo_igual #Aqui va la afijacion de la muestra
D = 500 # D es igual a la varianza de ybar o tmbien B^2/Z^2
tamaño_n = sum(((Nh^2*s2h)/wh))/(N^2*D+sum(Nh*s2h))
tamaño_n
asignacion = wh*tamaño_n
asignacion
B= 5000 #Limite del error  B = 2*raiz varianza=5000
Z = 2 #qnorm(0.975)
wh_optima_costo_igual = (Nh*sh)/(sum(Nh*sh)) #Neyman
wh = wh_optima_costo_igual #Aqui va la afijacion de la muestra
D = 800 # D es igual a la varianza de ybar o tmbien B^2/Z^2
tamaño_n = sum(((Nh^2*s2h)/wh))/(N^2*D+sum(Nh*s2h))
tamaño_n
asignacion = wh*tamaño_n
asignacion
B= 5000 #Limite del error  B = 2*raiz varianza=5000
Z = 2 #qnorm(0.975)
wh_optima_costo_igual = (Nh*sh)/(sum(Nh*sh)) #Neyman
wh = wh_optima_costo_igual #Aqui va la afijacion de la muestra
D = B^2/Z^2 # D es igual a la varianza de ybar o tmbien B^2/Z^2
tamaño_n = sum(((Nh^2*s2h)/wh))/(N^2*D+sum(Nh*s2h))
tamaño_n
asignacion = wh*tamaño_n
asignacion
B= 5000 #Limite del error  B = 2*raiz varianza=5000
Z = 2 #qnorm(0.975)
wh_optima_costo_igual = (Nh*sh)/(sum(Nh*sh)) #Neyman
wh = wh_optima_costo_igual #Aqui va la afijacion de la muestra
D = 2500 # D es igual a la varianza de ybar o tmbien B^2/Z^2
tamaño_n = sum(((Nh^2*s2h)/wh))/(N^2*D+sum(Nh*s2h))
tamaño_n
asignacion = wh*tamaño_n
asignacion
n
N
nh
n
NH
Nh
nh
b) Si el estudio es con un LEE de 5000 encuentre tamaño muestra con Neyman.
Con este dato, se esta fijando a B en 5 mil
n=(sum((Nh^2*s2h/wh)))/((N^2*D)+sum(Nh*s2h)) #Formula tamaño muestral.
Para ello, se necesita calcular
sh = sqrt(s2h)
wh=(Nh*sh)/(sum(Nh*sh)) #Afijacion optima de neyman (costo igual)
D = 5000^2/(2^2*N^2)
Finalmente, se usa la formula del tamaño muestral n
n=(sum((Nh^2*s2h/wh)))/((N^2*D)+sum(Nh*s2h)) #Formula tamaño muestral.
B= 5000 #Limite del error  B = 2*raiz varianza=5000
Z = 2 #qnorm(0.975)
wh_optima_costo_igual = (Nh*sh)/(sum(Nh*sh)) #Neyman
wh = wh_optima_costo_igual #Aqui va la afijacion de la muestra
D = B^2/(Z^2*N^2) # D es igual a la varianza de ybar o tmbien B^2/(Z^2*N^2)
tamaño_n = sum(((Nh^2*s2h)/wh))/(N^2*D+sum(Nh*s2h))
tamaño_n
asignacion = wh*tamaño_n
asignacion
D
var_y_est
Nh = c(86,72,52,30)
nh = c(14,12,9,5)
N = sum(Nh)
n = sum(nh)
estrato_1 = c(97,42,25,105,27,45,53,67,125,92,86,43,59,21)
estrato_2 = c(125,67,256,310,220,142,155,96,47,236,352,190)
estrato_3 = c(142,310,495,320,196,256,440,510,396)
estrato_4 = c(167,220,780,655,540)
y_h = c(mean(estrato_1),mean(estrato_2),mean(estrato_3),mean(estrato_4)) #Será el promedio en cada estrato
y_bar_est = sum((Nh/N)*y_h)
y_bar_est
t_est= sum(N*y_bar_est)
t_est
s2h = c(var(estrato_1),var(estrato_2),var(estrato_3),var(estrato_4)) #varianza
sh = sqrt(s2h)
var_yh_bar= (1-nh/Nh)*s2h/nh #Varianza de Y-Barra para cada estrato
var_y_est = 1/N^2*sum(Nh^2*var_yh_bar) # Varianza media estratificada
var_y_est
varianzaEstimadorMediaEstrarificada <- function(Nh, Varhaty){
N <- sum(Nh)
sum(Nh^2 * Varhaty)/(N^2)
}
varianzaEstimadorMediaEstrarificada(Nh,s2h)
varianzaEstimadorMediaEstrarificada(Nh,sh)
varianzaEstimadorMediaEstrarificada(Nh,s2h)
s2h = c(var(estrato_1),var(estrato_2),var(estrato_3),var(estrato_4)) #varianza
sh = sqrt(s2h)
var_yh_bar= (1-nh/Nh)*s2h/nh #Varianza de Y-Barra para cada estrato
var_y_est = 1/N^2*sum(Nh^2*var_yh_bar) # Varianza media estratificada
var_y_est
varianzaEstimadorMediaEstrarificada(Nh,s2h)
B= 5000 #Limite del error  B = 2*raiz varianza=5000
Z = 2 #qnorm(0.975)
wh_optima_costo_igual = (Nh*sh)/(sum(Nh*sh)) #Neyman
wh = wh_optima_costo_igual #Aqui va la afijacion de la muestra
D = B^2/(Z^2*N^2) # D es igual a la varianza de ybar o tmbien B^2/(Z^2*N^2) cuando se calcula el total poblacional
tamaño_n = sum(((Nh^2*s2h)/wh))/(N^2*D+sum(Nh*s2h))
tamaño_n
asignacion = wh*tamaño_n
asignacion
n
Si el estudio es con un LEE de 5000 encuentre tamaño muestra con Neyman.
Con este dato, se esta fijando a B en 5 mil
n=(sum((Nh^2*s2h/wh)))/((N^2*D)+sum(Nh*s2h)) #Formula tamaño muestral.
Para ello, se necesita calcular
sh = sqrt(s2h)
wh=(Nh*sh)/(sum(Nh*sh)) #Afijacion optima de neyman (costo igual)
D = 5000^2/(2^2*N^2)
Finalmente, se usa la formula del tamaño muestral n
n=(sum((Nh^2*s2h/wh)))/((N^2*D)+sum(Nh*s2h)) #Formula tamaño muestral.
n
B= 5000 #Limite del error  B = 2*raiz varianza=5000
Z = 2 #qnorm(0.975)
wh_optima_costo_igual = (Nh*sh)/(sum(Nh*sh)) #Neyman
wh = wh_optima_costo_igual #Aqui va la afijacion de la muestra
D = B^2/(Z^2*N^2) # D es igual a la varianza de ybar o tmbien B^2/(Z^2*N^2) cuando se calcula el total poblacional
tamaño_n = sum(((Nh^2*s2h)/wh))/(N^2*D+sum(Nh*s2h))
tamaño_n
asignacion = wh*tamaño_n
ceiling(asignacion)
wh_optima_costo_igual = (Nh*sh)/(sum(Nh*sh)) #Neyman
B= 1 #Limite del error
wh = wh_optima_costo_igual #Aqui va la afijacion de la muestra
D = B^2/(Z^2) # D es igual a la varianza de ybar estratificado
#OJO: D ES IGUALA B^2/Z^2 NE GENERAL PERO, PARA CALCULAR EL **TOTAL** POBLACIONAL, SE USA LA EXPRESION DE D = B^2/(Z^2* #N^2) dividido sobre N cuadrado
n_optimo = sum(((Nh^2*s2h)/wh))/(N^2*D+sum(Nh*s2h))
n_optimo
asignacion = wh*n_optimo
asignacion
ceiling(asignacion)
N
N= 96
Nh = c(43,53)
sigma1 = (20-5)/6 #varianza hombres NO SABEMOS POR QUE PUTAS
sigma2= (14-3)/6 #Varianza mujeres
sh = c(sigma1,sigma2)
s2h = sh^2
wh_optima_costo_igual = (Nh*sh)/(sum(Nh*sh)) #Neyman
B= 1 #Limite del error
wh = wh_optima_costo_igual #Aqui va la afijacion de la muestra
D = B^2/(Z^2) # D es igual a la varianza de ybar estratificado
#OJO: D ES IGUALA B^2/Z^2 NE GENERAL PERO, PARA CALCULAR EL **TOTAL** POBLACIONAL, SE USA LA EXPRESION DE D = B^2/(Z^2* #N^2) dividido sobre N cuadrado
n_optimo = sum(((Nh^2*s2h)/wh))/(N^2*D+sum(Nh*s2h))
n_optimo
asignacion = wh*n_optimo
asignacion
Punto 9:
N= 96
Nh = c(43,53)
sigma1 = (20-5)/6 #varianza hombres
sigma2= (14-3)/6 #Varianza mujeres
sh = c(sigma1,sigma2)
s2h = sh^2
#Costos iguales
wh=(Nh*sh)/(sum(Nh*sh)) #Afijacion optima de neyman (costo igual)
B=1
D=B^2/2^2
n=(sum((Nh^2*s2h/wh)))/((N^2*D)+sum(Nh*s2h)) #Formula tamaño muestral.
ceiling(n)
n
Usuarios_Estratos=c(97,43,145,68)
personas_urbanos=c(97,43)
personas_rural = c(145,68)
proporcion_urbana=97/sum(personas_urbanos) #Proporcion pers urban. Asisten
proporcion_rural=145/sum(personas_rural) #Proporcion, rural, no asisten
ph = c(proporcion_urbana,proporcion_rural)
qh = 1-ph
Usuarios_Estratos=c(97,43,145,68)
personas_urbanos=c(97,43)
personas_rural = c(145,68)
proporcion_urbana=97/sum(personas_urbanos) #Proporcion pers urban. Asisten
proporcion_rural=145/sum(personas_rural) #Proporcion, rural, no asisten
ph = c(proporcion_urbana,proporcion_rural)
qh = 1-ph
qh
ph
varianza = ph*qh
N = sum(Usuarios_Estratos)
p_est = 1/N*sum(Usuarios_Estratos*ph)
Varianza_Pest = 1/N^2*sum(Usuarios_Estratos^2*varianza)
raiz_varianza = sqrt(Varianza_Pest)
p_est
varianza = ph*qh
N = sum(Usuarios_Estratos)
Nh = Usuarios_Estratos
p_est = sum((Nh/N)*ph)
Varianza_Pest = 1/N^2*sum(Usuarios_Estratos^2*varianza)
raiz_varianza = sqrt(Varianza_Pest)
p_est
varianza = ph*qh
N = sum(Usuarios_Estratos)
Nh = Usuarios_Estratos
p_est = sum((Nh/N)*ph)
var_p_est = 1/N^2*sum(Nh^2*varianza)
var_p_est
Varianza_Pest = 1/N^2*sum(Usuarios_Estratos^2*varianza)
Varianza_Pest
B= 0.05 #Limite del error
Z = qnorm(0.975)
s2h = varianza #Sigma cuadrado sacado de la mmuestra
# ESTA FORMULA SE REEMPLAZA TAMAÑO n
ch = c(4,8)
sh = sqrt(s2h)
numerador = (Nh*sh)/(sqrt(ch))
denominador = sum((Nh*sh)/(sqrt(ch)))
wh_optmina_muestra = numerador/denominador
wh = wh_optmina_muestra #Aqui va la afijacion de la muestra
D = B^2/(Z^2) # D es igual a la varianza de ybar estratificado
#OJO: D ES IGUALA B^2/Z^2 NE GENERAL PERO, PARA CALCULAR EL **TOTAL** POBLACIONAL, SE USA LA EXPRESION DE D = B^2/(Z^2* #N^2) dividido sobre N cuadrado
n_optimo = sum(((Nh^2*s2h)/wh))/(N^2*D+sum(Nh*s2h))
n_optimo
asignacion = wh*n_optimo
asignacion
Usuarios_Estratos=c(97,43,145,68)
personas_urbanos=c(97,43)
personas_rural = c(145,68)
proporcion_urbana=97/sum(personas_urbanos) #Proporcion pers urban. Asisten
proporcion_rural=145/sum(personas_rural) #Proporcion, rural,  asisten
ph = c(proporcion_urbana,proporcion_rural) #Proporcion asistentes
qh = 1-ph
varianza = ph*qh
N = sum(Usuarios_Estratos)
Nh = Usuarios_Estratos
p_est = sum((Nh/N)*ph)
var_p_est = 1/N^2*sum(Nh^2*varianza)
N
nh
Nh
145+97+43+68
N
Nh
varianza
varianza = ph*qh
N = sum(Usuarios_Estratos)
Nh = Usuarios_Estratos
p_est = sum((Nh/N)*ph)
var_p_est = 1/N^2*sum(Nh^2*varianza)
var_p_est
B= 0.05 #Limite del error
Z = qnorm(0.975)
s2h = var_p_est #Sigma cuadrado sacado de la mmuestra
# ESTA FORMULA SE REEMPLAZA TAMAÑO n
ch = c(4,8)
sh = sqrt(s2h)
numerador = (Nh*sh)/(sqrt(ch))
denominador = sum((Nh*sh)/(sqrt(ch)))
wh_optmina_muestra = numerador/denominador
wh = wh_optmina_muestra #Aqui va la afijacion de la muestra
D = B^2/(Z^2) # D es igual a la varianza de ybar estratificado
#OJO: D ES IGUALA B^2/Z^2 NE GENERAL PERO, PARA CALCULAR EL **TOTAL** POBLACIONAL, SE USA LA EXPRESION DE D = B^2/(Z^2* #N^2) dividido sobre N cuadrado
n_optimo = sum(((Nh^2*s2h)/wh))/(N^2*D+sum(Nh*s2h))
n_optimo
asignacion = wh*n_optimo
asignacion
Nh
N
ph = c(0.87,0.93,0.6,0.53)
p_est = sum((Nh/N)*ph)
A_est = N*p_est
p_est
A_est
n
nh
#Calculo de varianzas nuevas
ph
#Calculo de varianzas nuevas
qh = 1-ph
#Recuerde que varianza proporcion esta dada por:
#p*(1-p)/(n-1)*(N-n)/N
var_ph = ph*qh
var_p_est = 1/N^2*sum(Nh^2*var_ph)
var_p_est
#Calculo de varianzas nuevas
qh = 1-ph
#Recuerde que varianza proporcion esta dada por:
#p*(1-p)/(n-1)*(N-n)/N
var_ph = ph*qh
var_p_est = 1/N^2*sum(Nh^2*var_ph)
var_p_est
B=2*sqrt(var_p_est)
#Calculo de varianzas nuevas
qh = 1-ph
#Recuerde que varianza proporcion esta dada por:
#p*(1-p)/(n-1)*(N-n)/N
var_ph = ph*qh
var_p_est = 1/N^2*sum(Nh^2*var_ph)
var_p_est
B=2*sqrt(var_p_est)
B
ph = c(0.87,0.93,0.6,0.53)
Usuarios_Estratos=c(97,43,145,68) #Este es Nh
Usaran = Usuarios_Estratos*ph
NoUsaran = Usuarios_Estratos-Usaran
N = sum(Usuarios_Estratos)
P_est = sum(ph*Usuarios_Estratos)/N
P_est
qh= 1-ph
varianza_ph = ph*qh
varianzaP_est= 1/N^2*sum(Usuarios_Estratos^2*varianza_ph)
IC = c(P_est-varianzaP_est,P_est+varianzaP_est)
IC
IC
varianzaP_est
2*sqrt(varianzaP_est)
P_est-0.4868028
P_est+0.4868028
P_est+0.4868028
P_est
library(car)
library(rsm)
library(rgl)
library(perturb)
library(leaps)
library(scatterplot3d)
library(olsrr)
library(GGally)
library(rgl)
install.packages("perturb")
miscoeficientes=function(modeloreg,datosreg){
coefi=coef(modeloreg)
datos2=as.data.frame(scale(datosreg))
coef.std=c(0,coef(lm(update(formula(modeloreg),~.+0),datos2)))
limites=confint(modeloreg,level=0.95)
vifs=c(0,vif(modeloreg))
resul=data.frame(Estimación=coefi,Limites=limites,Vif=vifs,Coef.Std=coef.std)
cat("Coeficientes estimados, sus I.C, Vifs y Coeficientes estimados estandarizados","\n")
resul
}
datos=read.table(file.choose(),header=T,sep=',')#Leer datos datosRLMCMLOPERA.csv
attach(datos)
names(datos)
gg2<-ggpairs(datos,upper=list(continuous = wrap("smooth",alpha = 0.3, size=1.2,method = "lm")),lower=list(continuous ="cor"))
for(i in 1:ncol(datos)){
gg2[i,i]<-gg2[i,i]+
geom_histogram(breaks=hist(datos[,i],breaks = "FD",plot=F)$breaks,
colour = "red",fill="lightgoldenrod1")
}
gg2<-ggpairs(datos,upper=list(continuous = wrap("smooth",alpha = 0.3, size=1.2,method = "lm")),lower=list(continuous ="cor"))
for(i in 1:ncol(datos)){
gg2[i,i]<-gg2[i,i]+
geom_histogram(breaks=hist(datos[,i],breaks = "FD",plot=F)$breaks,
colour = "red",fill="lightgoldenrod1")
}
win.graph()
gg2<-ggpairs(datos,upper=list(continuous = wrap("smooth",alpha = 0.3, size=1.2,method = "lm")),lower=list(continuous ="cor"))
for(i in 1:ncol(datos)){
gg2[i,i]<-gg2[i,i]+
geom_histogram(breaks=hist(datos[,i],breaks = "FD",plot=F)$breaks,
colour = "red",fill="lightgoldenrod1")
}
win.graph()
gg2
win.graph()
ggpairs(datos,diag=list(continuous=wrap("box_no_facet",color="red",fill="lightgoldenrod1",alpha=0.3)),upper=list(continuous = wrap("smooth",alpha = 0.3, size=1.2,method = "lm")),lower=list(continuous ="cor"))
modelo=lm(Y~.,datos[-1]) #No se considera la primera columna de datos que es el ID
summary(modelo)
View(modelo)
summary(modelo)
anova(rsm(Y~FO(X1,X2,X3,X4,X5,X6,X7,X8,X9)))
residualPlots(modelo,tests=FALSE,type="rstudent",quadratic=FALSE,col=2,cex=1.5)
test=shapiro.test(rstudent(modelo)) #Test de normalidad sobre residuales estudentizados
qqnorm(rstudent(modelo),cex=2)
qqline(rstudent(modelo),col=2)
legend("topleft",legend=rbind(c("Statistic W","p.value"),round(c(test$statistic,test$p.value),digits=5)),cex=0.5)
residualPlots(modelo,tests=FALSE,type="rstudent",quadratic=FALSE,col=2,cex=1.5)
test=shapiro.test(rstudent(modelo)) #Test de normalidad sobre residuales estudentizados
qqnorm(rstudent(modelo),cex=2)
qqline(rstudent(modelo),col=2)
legend("topleft",legend=rbind(c("Statistic W","p.value"),round(c(test$statistic,test$p.value),digits=5)),cex=0.5)
View(datos)
anova(rsm(Y~FO(X1,X2,X3,X4,X5,X6,X7,X8,X9)))
residualPlots(modelo,tests=FALSE,type="rstudent",quadratic=FALSE,col=2,cex=1.5)
residualPlots(modelo,tests=FALSE,type="rstudent",quadratic=FALSE,col=2,cex=1.5)
residualPlots(modelo,tests=FALSE,type="rstudent",quadratic=FALSE,col=2,cex=1.5)
win.graph()
residualPlots(modelo,tests=FALSE,type="rstudent",quadratic=FALSE,col=2,cex=1.5)
miscoeficientes(modelo,datos[-1])
influence.measures(modelo)
influence.measures(modelo)$is.inf
a=influence.measures(modelo)$is.inf
View(a)
infIndexPlot(modelo)
influencePlot(modelo,xlim=c(0,1),ylim=c(-6.0,4.5))
infIndexPlot(modelo)
influencePlot(modelo,xlim=c(0,1),ylim=c(-6.0,4.5))
influencePlot(modelo,xlim=c(0,1),ylim=c(-6.0,4.5))
dfbetaPlots(modelo,intercept=T,cex=2,col=2)
win.graph()
dfbetaPlots(modelo,intercept=T,cex=2,col=2)
#con datos centrados
Ind=colldiag(modelo,center=TRUE)
X=model.matrix(modelo)[,-1]
val.prop=prcomp(X,center=TRUE,scale=TRUE)$sdev^2
resul=data.frame(Val.propio=val.prop,Ind.Cond=Ind$condindx,Pi=Ind$pi)
resul
#con datos centrados
Ind=colldiag(modelo,center=TRUE)
View(miscoeficientes)
function(modeloreg,datosreg){
coefi=coef(modeloreg)
datos2=as.data.frame(scale(datosreg))
coef.std=c(0,coef(lm(update(formula(modeloreg),~.+0),datos2)))
limites=confint(modeloreg,level=0.95)
vifs=c(0,vif(modeloreg))
resul=data.frame(Estimaci�n=coefi,Limites=limites,Vif=vifs,Coef.Std=coef.std)
cat("Coeficientes estimados, sus I.C, Vifs y Coeficientes estimados estandarizados","\n")
resul
}
miscoeficientes(modelo,datos[-1])
miscoeficientes(modelo,datos([-1]))
miscoeficientes(modelo,datos[-1])
miscoeficientes(modelo,datos[-1])
influence.measures(modelo)
a=influence.measures(modelo)$is.inf
infIndexPlot(modelo)
influencePlot(modelo,xlim=c(0,1),ylim=c(-6.0,4.5))
dfbetaPlots(modelo,intercept=T,cex=2,col=2)
#con datos centrados
Ind=colldiag(modelo,center=TRUE)
X=model.matrix(modelo)[,-1]
val.prop=prcomp(X,center=TRUE,scale=TRUE)$sdev^2
resul=data.frame(Val.propio=val.prop,Ind.Cond=Ind$condindx,Pi=Ind$pi)
resul
resul=data.frame(Val.propio=val.prop,Ind.Cond=Ind$condindx,Pi=Ind$pi)
dfbetaPlots(modelo,intercept=T,cex=2,col=2)
influencePlot(modelo,xlim=c(0,1),ylim=c(-6.0,4.5))
dfbetaPlots(modelo,intercept=T,cex=2,col=2)
X=model.matrix(modelo)[,-1]
val.prop=prcomp(X,center=TRUE,scale=TRUE)$sdev^2
resul=data.frame(Val.propio=val.prop,Ind.Cond=Ind$condindx,Pi=Ind$pi)
resul
#con datos centrados
Ind=colldiag(modelo,center=TRUE)
library(car)
library(rsm)
library(rgl)
library(perturb)
library(perturb)
install.packages("C:/Users/jhsga/Downloads/perturb_2.10.tar.gz", repos = NULL, type = "source")
library(perturb)
1+1
library(xfun)
detach("package:xfun", unload = TRUE)
