---
title: ''
author: ''
date: ''
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(rsm)
library(car)
library(leaps)
library(scatterplot3d)
library(GGally)
library(olsrr)
library(perturb)
library(olsrr)
```


$\rule{6.5in}{1pt}$
\begin{center}

\textbf{UNIVERSIDAD NACIONAL DE COLOMBIA}

\textit{REGRESIÓN LINEAL MULTIPLE PARTE 1}

\textbf{Autor:}

\textit{Daniela Pico}

\textit{Jhonatan Smith}

\textbf{Profesor:}

\textit{Isabel Cristina Ramirez}

\textbf{2021-01}
\end{center}

$\rule{6.5in}{1pt}$

1. Ajuste un modelo de regresión lineal múltiple, muestre la tabla de parámetros ajustados y escriba la ecuación ajustada. Calcule la Anova del modelo Es significativo el modelo? ¿Qué proporción de la variabilidad total de la respuesta es explicada por el modelo? Opine sobre esto úlltimo.

2. Calcule los coeficientes de regresión estandarizados y concluya acerca de cúal de las variables aporta más a la respuesta según la magnitud en valor absoluto de tales coeficientes (cuidado, no confunda esto con la significancia de los coeficientes de regresión).

3. Pruebe la significancia individual de cada uno de los parámetros del modelo (excepto intercepto), usando la prueba t, y para dos cualesquiera de las predictoras, usando la prueba F con sumas de cuadrados extras con test lineal general; en cada caso, especifique claramente el modelo reducido y completo, estadistico de la prueba, su distribución, cálculo de valor P, decisión y conclusión a la luz de los datos.

4. Calcule las sumas de cuadrados tipo I (secuenciales) y tipo II (parciales) ¿Cuál de las variables tienen menor valor en tales sumas? ¿Que puede significar ello?

5. Construya y analice gráficos de los residuales estudentizados vs. Valores ajustados y contra las variables de regresión utilizadas. Qué información proporcionan estas gráficas?

6. Construya una gráfica de probabilidad normal para los residuales estudentizados. ¿Existen razones para dudar de la hipótesis de normalidad sobre los errores en este modelo?

7. Diagnostique la presencia de observaciones atipicas, de balanceo y/o influenciales. Recuerde que cada unidad de observación es una institución hospitalaria. En particular, ¿las observaciones  ID = 47 e ID = 112 se diferencian del resto? Ajuste el modelo de regresión sin estas dos observaciones, presente solo la tabla de parámetros ajustados resultante ¿Cambian notoriamente las estimaciones de los parámetros, sus errores estandard y/o la significancia? ¿Qué concluye al respecto? Evalúe el gráfico de normalidad para los residuales estudentizados para este ajuste ¿mejoró la normalidad? Concluya sobre los efectos de este par de observaciones.

8. Para el modelo con todas las variables y sin las observaciones con ID = 47 e ID = 112, realice diagnósticos de multicolinealidad mediante

* Matriz de correlación de las variables predictoras
 * VIF's
  * Proporciones de varianza

9. En el modelo ajustado sin las observaciones con ID = 47 e ID = 112, construya modelos de regresión utilizando los métodos de selección (muestre de cada método sólo la tabla de resumen de este y la tabla ANOVA y la de parámetros estimados del modelo ánalogamente resultante):

* Selección según el R2
adj
 * Selección según el estadadístico Cp
  * Stepwise
   * Selección hacia adelante o forward
    * Selección hacia atrás o backward

10. Con base en los anteriores numerales, ¿Cúal modelo sugiere para la variable respuesta? ¿por qué?

```{r, echo=FALSE}
data=read.table(file.choose(),header=T,sep=";",dec=",",
colClasses=c(rep("numeric",7),"factor",rep("numeric",3),"factor"))
```

```{r, echo=FALSE, include=FALSE}
data$REGION <- NULL
data$AEM <- NULL
data$ID <- NULL
attach(data)
View(data)
```


```{r eval=FALSE, include=FALSE}
attach(data)
```



 \newpage

\begin{center}

\textbf{Resultados}

\end{center}

1. El siguiente informe proporciona datos recolectados de un estudio sobre la eficacia del control de infecciones nosocomiales, cuyo objetivo principal fue determinar si los programas de vigilancia y control de infecciones han reducido las tasas de infección nosocomialen hospitales de Estados Unidos. Estos datos consisten de una muestra aleatoria de n = 80; 90; 100; 70; 65; 85 hospitales, respectivamente, seleccionados de los 338 hospitales originales investigados. Los datos presentados corresponden al periodo de estudio 1975-76. Se presentaron las siguientes variables:

* ID: Número de indentificación de registro.
 * DPERM: Longitud de permanencia.
  * EDAD: Edad.
   * RINF: Riesgo de infección.

     
* RRX: Razón de rutina de rayos X del pecho.
 * NCAMAS: Número de camas.
  * AEM: Afiliación de escuela de medicina.
   * PDP: Censo promedio diario.
         
* NENFERM: Número de enfermeras.
 * FSD: Facilidades y servicios disponibles.
  * REGION: Región.
   * RRC: Razón de rutina de cultivos.

Se desea estudiar la longitud de permanencia (Y) en función de las variables predictorias:

* $X_1$= EDAD
 * $X_2$= RINF
  * $X_3$= RRC
   * $X_4$= RRX
* $X_5$= NCAMAS
 * $X_6$= PDP
  * $X_7$= NENFERM
   * $X_8$= FSD
   
En primera instancia se realiza un analisis descriptivo del comportamiento de los datos a través de un gráfico de dispersión.

```{r eval=FALSE, include=FALSE}
gg2<-ggpairs(data,upper=list(continuous = wrap("smooth",alpha = 0.3, size=1.2,method = "lm")),lower=list(continuous ="cor"))
for(i in 1:ncol(data)){
  gg2[i,i]<-gg2[i,i]+
    geom_histogram(breaks=hist(data[,i],breaks = "FD",plot=F)$breaks,
                   colour = "red",fill="lightgoldenrod1")
}
```

```{r eval=FALSE, include=FALSE}
win.graph()
gg2
```





Se plantea un modelo de RLM para el problema:
$$Y_i = \beta_0 + \beta_1X_{i1} + \beta_2X_{i2} + \cdots+ \beta_8X_{i8}  + \varepsilon_i, \quad i = 1, 2, \ldots, 80$$
Que tiene como supuestos lo siguiente:
$$\varepsilon_i \overset{\text{iid}}{\sim} N\left(0,\sigma ^2 \right), \quad i = 1, 2, \ldots, 80$$

También se puede especificar el modelo en términos matriciales, así:
$$\boldsymbol{y} = \boldsymbol{X\beta} + \boldsymbol{\varepsilon} \quad \text{ con }\quad \boldsymbol{\varepsilon}\sim\boldsymbol{N}(\boldsymbol{0}, \sigma^2\boldsymbol{I})$$
 \newpage

**Especificación del modelo de RLM, ANOVA y parámetros estimados**

```{r, echo=FALSE}
myAnova <- function(lm.model){
 SSq <- unlist(anova(lm.model)["Sum Sq"])
 k <- length(SSq) - 1
 SSR <- sum(SSq[1:k])
 SSE <- SSq[(k + 1)]
 MSR <- SSR/k
 df.error <- unlist(anova(lm.model)["Df"])[k + 1]
 MSE <- SSE/df.error
 F0 <- MSR/MSE
 PV <- pf(F0, k, df.error, lower.tail = F)
 result<-data.frame(Sum_of_Squares = format(c(SSR, SSE), digits = 6), DF = format(c(k, df.error), digits = 6),
                    Mean_Square = format(c(MSR, MSE), digits = 6), F_Value = c(format(F0, digits = 6), ''),
                    P_value = c(format(PV, digits = 6), ''), row.names = c("Model", "Error"))
 result
}
```

    ```{r, echo=FALSE, warning=FALSE, comment=FALSE, results="asis", message=FALSE, size=20}
    # Ajuste del modelo de RLM
    modelo=lm(DPERM~EDAD+RINF+RRC+RRX+NCAMAS+PDP+NENFERM+FSD)
    summary(modelo)

   # ANOVA
   myAnova(modelo)
  
    ```



**El modelo ajustado es:**
$$Y_i = -1.052672 +0.112843X_{i1} + 0.478359X_{i2} + 0.019804X_{i3} + 0.018959X_{i4} - 0.010422X_{i5} + 0.023132X_{i6}$$$$ - 0.007527X_{i7} + 0.004740X_{i8}  + \varepsilon_i$$ $$ \quad i = 1, 2, \ldots, 80$$

**Prueba de Significancia de la regresión**
    
Se quiere probar:
$$
\begin{aligned}
H_0:&\ \beta_1 = \beta_2 = \cdots = \beta_8 = 0, \quad \text{ vs.}\\
H_1:&\ \text{Algún } \beta_j \neq 0, j = 1, \ldots, 8.
\end{aligned}
$$
    
Para ello se usa la tabla de análisis de varianza. De ella se obtienen los valores del estadístico de prueba $F_0 =14.7988$ y su correspondiente valor-P $\text{vp} = 1.68478e-12$.

    
Como vp $< 0.05 = \alpha$ se rechaza $H_0$ concluyendo que el modelo de RLM propuesto es significativo. Esto quiere decir, que la logitud de permanencia es afectada significativamente por al menos una de las predictoras consideradas.


\newpage

**Cálculo e interpretación del coeficiente de determinación**

Sabemos que $R^2 = \frac{\text{SSR}}{\text{SST}} = 1 - \frac{\text{SSE}}{\text{SST}}$, de manera que se puede calcular de la tabla ANOVA.
$$R^2 = \frac{\text{SSR}}{\text{SST}} = \frac{221.000}{221.000 + 132.537} = 221.000/(221.000 + 132.537)`$$
    
Según el $R^{2}$ el 62.51% de la variabilidad total de la longitud de permanencia es explicado por el modelo propuesto.
    
Por otro lado, se puede calcular el $R^2$ ajustado como una medida de bondad de ajuste, así:
$$R_{\text{adj}}^2 = 1 - \frac{\left(n - 1\right)\text{MSE}}{\text{SST}} = 1 - \frac{\left(80 - 1\right)1.86671}{221.000 + 132.537} = `r 1 - (80 - 1)*1.86671/(221.000 + 132.537)`$$
Según el $R^{2} ajustado$ el 58.29% de la variabilidad total de la longitud de permanencia es explicado por el modelo propuesto.

Teniendo en cuenta que $R^2_{adj}$ penaliza la varianza a medida que se agregan covariables (factor que no tiene en cuenta por si solo R^2) se prefiere usar para el caso de Regresion Lineal Multiple (RLM) el ajustado. 

2. Como los $X_j$ tienen diferente escala de medida, no se puede determinar cual de ellas tiene mayor o menor efecto parcial sobre la respuesta media, por esto tiene sentido realizar una estandarización de las variables, de tal forma que queden en la misma escala y puedan ser comparadas.

```{r, echo=FALSE}
miscoeficientes=function(modeloreg,datosreg){
coefi=coef(modeloreg)
datos2=as.data.frame(scale(datosreg))
coef.std=c(0,coef(lm(update(formula(modeloreg),~.+0),datos2)))
resul=data.frame(Estimacion=coefi, Coef.Std=coef.std)
cat("Coeficientes estimados y Coeficientes estimados estandarizados","\n")
resul
}
```

```{r, echo=FALSE}
miscoeficientes(modelo,data)
```


Según la magnitud del valor absoluto de los coeficientes estudentizados la variable que tiene mayor efecto en la respuesta será el censo promedio diario (PDP) con un valor de 1.61358192	 y la variable con menor efecto en la respuesta media es facilidades y servicios disponibles(FSD) con un valor de 0.03301155

3. **Prueba de significancia individual de los parametros usando la prueba t**

Estas pruebas establecen el siguiente juego de hipótesis:
$$\begin{array}{l} H_0: \beta_j = 0\\ H_1: \beta_j \ne 0 \end{array}\ \text{ para }\ j = 1, 2, \ldots, 8.$$
De la tabla de parámetros estimados, a un nivel de significancia $\alpha = 0.05$ se rechaza $H_0$ si $\left | T_0 \right |> T_\frac{\alpha }{2} ,n-k-1$

Para este caso con la $T_{(1-\frac{0.05}{2},71)}=1.993943$ basta comparar con los datos suministrados en la tabla anterior en la columna de t-values:

 * $EDAD=\left | 3.116   \right |$ > 1.99
  * $RINF=\left | 3.045\right |$ > 1.99
   * $RRC=\left | 1.053 \right |$ < 1.99
    
 * $RRX=\left | 2.080  \right |$ > 1.99
  * $NCAMAS=\left | -2.226 \right |$ > 1.99
   * $PDP=\left | 4.392 \right |$ > 1.99

 * $NENFERM=\left | -2.458 \right |$ > 1.99
  * $FSD=\left | 0.277 \right |$ < 1.99

Se concluye que los parámetros individuales $\beta_1,\beta_2,\beta_4, \beta_5,\beta_6,\beta_7$ son significativos cada uno en presencia de los demás parámetros; por otro lado, se encuentra que $\beta_3,\beta_8$ son individualmente no significativos en presencia de los demás parámetros.

**Interpretación de los parámetros estimados**

$\widehat\beta_1 = 0.112843$ indica que por cada unidad de aumento en la edad el promedio de la longitud de permanencia aumenta en 0.112843 unidades, cuando las demás variables predictoras se mantienen fijas. 

$\widehat \beta_2 = 0.478359$ indica que por cada unidad de aumento en el riesgo de infección el promedio de la longitud de permanencia aumenta en 0.478359 unidades, cuando las demás variables predictoras se mantienen fijas.

$\widehat \beta_4 = 0.018959$ indica que por cada unidad de aumento en la razón de rutinas de rayos X en el pecho el promedio de la longitud de permanencia aumenta en 0.018959 unidades, cuando las demás variables predictoras se mantienen fijas.

$\widehat \beta_5 = -0.010422$ indica que por cada unidad de aumento en el número de camas el promedio de la longitud de permanencia disminuye en 0.010422 unidades, cuando las demás variables predictoras se mantienen fijas.
    
$\widehat \beta_6 = 0.023132$ indica que por cada unidad de aumento en el censo promedio diario el promedio de la longitud de permanencia aumenta en 0.023132 unidades, cuando las demás variables predictoras se mantienen fijas.

$\widehat\beta_7 = -0.007527$ indica que por cada unidad de aumento en el numero de enfermeras el promedio de la longitud de permanencia disminuye  en 0.007527 unidades, cuando las demás variables predictoras se mantienen fijas.




**Prueba F con sumas de cuadrados extras**

Para esta prueba se elegiran convenientemente Dos parametros no significativos del modelo, en este caso $\beta_3$ y $\beta_8$. Se plantean las siguientes hipotesis:

$$H_0:\ \beta_3 = \beta_8 = 0\quad \text{ vs. }\quad H_1:\ \text{Algún }\beta_j\neq 0, \ j = 3, 8$$
Esta prueba se desarrolla usando sumas de cuadrados extra y se requiere la tabla de todas las regresiones posibles como se presenta a continuación.

**Modelo FULL**

$$Y_i = \beta_0 + \beta_1X_{i1} + \beta_2X_{i2} + \cdots+ \beta_8X_{i8}  + \varepsilon_i, \quad i = 1, 2, \ldots, 80$$ $$ \varepsilon_i \overset{\text{iid}}{\sim} N\left(0,\sigma ^2 \right), \quad i = 1, 2, \ldots, 80$$ 
**Modelo reducido**
$$Y_i= \beta_0+\beta_1x_{i1}+\beta_2x_{i2}+\beta_4x_{i4}+\beta_5x_{i5}+\beta_6x_{i6}+\beta_7x_{i7}+E_i$$ $$ \varepsilon_i \overset{\text{iid}}{\sim} N\left(0,\sigma ^2 \right), \quad i = 1, 2, \ldots, 80$$
\newpage
**Estadistico de prueba F0**

$$F_0=\frac{(SSE(MR)-SSE(MF))/2}{MSE(MF)}$$ $$=\frac{(SSE(X_1,X_2,X_4,X_5,X_6,X_7)-SSE(X_1,X_2,X_3,X_4,X_5,X_6,X_7,X_8))/(n-7)-(n-9)}{MSE(X_1,X_2,X_3,X_4X_5,X_6,X_7,X_8))}$$$$=\frac{SSR(X_1,X_2,X_3,X_4,X_5,X_6,X_7,X_8|X_3,X_8)/2}{MSE(X_1,X_2,X_3,X_4,X_5,X_6,X_7,X_8)}\sim f_2,_{71}\space bajo\space H_0$$



```{r, echo=FALSE}
linearHypothesis(modelo,c("RRC=0","FSD=0"))
```

Para el criterio de decisión se requiere obtener el valor crítico de una distribución $f_{v, n-k-1}=f_{2,71}$ a un nivel de significancia $\alpha = 0.05$, esto es, $f_{0.05, 2,71} = `r qf(1 - 0.05, 2, 71)`$.
    
Como $F_0 =   0.5918 <  f_{0.05, 2, 87} =   3.1257642.$, entonces no se rechaza $H_0$ y se concluye que el conjunto de predictoras simultaneamente no son significativas, en presencia de los demás parámetros lo que implica que la variable RRC y FSD no son significativas para explicar la Longitud de permanencia. Notese que este resultado coincide con la prueba de significancia individual de los parametros.

4. **Suma de cuadrados Tipo I**
```{r, echo=FALSE}
a=anova(modelo)
a["Sum Sq"]
```

La suma de cuadrados extra tipo I de 1 grado de libertad agrega secuencialmente las variables según el orden establecido en el modelo full, es decir:

1) $SSR(EDAD)=33.536$ Y este es el resultado de ajustar la recta de regresio $Y_i= \beta_0+\beta_1*X_{i1}$ que es Longidtud de permanencia (DPERM) vs Edad
 
2) $SSR(RINF|EDAD)= 102.794$ Este es el incremento de SSR (Suma de cuadrados de la regresion) al ingresar la variable RINF al modelo de la longitud de permanencia dado que estaba la variable edad.

3) $SSR(RRC|EDAD,RINF)=2.147$ Es el incremento del SSR (Sumas de cuadrados de la regresion) al ingresar la variable RRC (Razon de rutina de cultivos) al modelo de la longitud de permanencia dado que estaban las variables edad y riesgo de infección.
 
Procediendo de la misma manera para cada uno de los casos, para el ultimo caso se tendria que:

* $SSR(FSD|EDAD,RINF,...,NENFERM)= 0.144$ Es el cambio marginal en SSR al ingresar la variable FSD (facilidad de servicios disponibles) al modelo de longitud de permanencia dado que estaban las anteriores predictoras, en este caso al ingresar la ultima covariable se presento la menor reducción marginal en la suma de cuadrados extras cuando las demás predictorias fueron agragadas al modelo. 

**Suma de cuadrados tipo II**

```{r, echo=FALSE}
Anova(modelo)
```
Las sumas SS2 corresponden a las sumas de cuadrados extras de cada variable ex-
plicatoria en el modelo, dadas las demas, decir:

1) $SSR(EDAD|RINF,RRX,NCAMAS,AEM,PDP,NENFERM,FSD)=18.125$: Este es el incremento de SSR (Suma de cuadrados de la regresion) al ingresar la variable edad al modelo de la longitud de permanencia dadas las demas variables en el modelo.

2)  $SSR(RINF|EDAD,RRX,NCAMAS,AEM,PDP,NENFERM,FSD)=17.306$: Este es el incremento de SSR (Suma de cuadrados de la regresion) al ingresar la variable riesgo de infeción al modelo de la longitud de permanencia dadas las demas variables en el modelo.

3) $SSR(RRX|EDAD,RINF,NCAMAS,AEM,PDP,NENFERM,FSD)=2.070$: Este es el incremento de SSR (Suma de cuadrados de la regresion) al ingresar la variable Razon de rutina de rayos X al modelo de la longitud de permanencia dadas las demas variables en el modelo.

Procediendo de la misma manera para cada uno de los casos, para el ultimo caso se tendria que:

* $SSR(FSD|EDAD,RINF,RRX,NCAMAS,AEM,PDP,NENFERM)=0.144$: Este es el incremento de SSR (Suma de cuadrados de la regresion) al ingresar la variable facilidad y servicios disponibles al modelo de la longitud de permanencia dadas las demas variables en el modelo.
En este caso al mirar el la suma de cuadrados de la regresión la menor fue al ingresar FSD dado que las demas predictorias estaban presentes en el modelo, note que para este caso en especifico, coincide con la suma de cuadrados Tipo I ya que el SSR calculado en teoría fue el mismo (0.144) y no hubo otro valor superior a este luego de realizar la suma de cuadrados tipo II

Las sumas de cuadrados secuenciales son especialmente utiles para realizar pruebas de hipotesis con una prueba F, esta prueba esta dada por $F_0=\frac{SSR(X_j|X_1,X_2,...,X_{k})}{MSE(X_1,X_2,...X_k)}$, Según esto un valor muy pequeño del SSR va a dar un valor pequeño en la $F_0$, por lo tanto, no se va a rechazar la hipotesis nula, lo que significa que el modelo no es significativo, en este caso, se puede afirmar que tiene sentido que la SSR(FSD|EDAD,RINF,RRX,NCAMAS,AEM,PDP,NENFERM)=0.144 tuviera menor suma de cuadrados extras ya que la covariable FSD no es significativa en presencia de los demás parametros.

A continuación se hara la prueba de significancia para sustentar esta idea

se quiere probar:

$$H_0:\beta_8=0$$ $$vs$$ $$H_a:\beta_8 \neq0$$
La $F_0=\frac{SSR(FSD|EDAD,RINF,RRX,NCAMAS,AEM,PDP,NENFERM)}{MSE(EDAD,RINF,RRX,NCAMAS,AEM,PDP,NENFERM,FSD)}=\frac{0.144}{1.8667}=0.0770$

se rechaza $H_0$ si $F_0>F_0.05,1,71$=3.98, como 0.0770<3.98, no se rechaza la hipotesis nula y se concluye que $\beta_8$ no es significativa en presencia de los demas parametros, esto quiere decir que no tiene un efecto significativo en el modelo de regresión cuando las demas variables permanencen constantes y se confirma lo mencionado anteriormente 

5. **Graficos de residuales estudentizados vs valores ajustados**

```{r, echo=FALSE}
residualPlots(modelo,tests=FALSE,type="rstudent",quadratic=FALSE,col=4,cex=1.0)
```

\newpage

**Interpretación**

1) Se observa que los datos son aleatorios alrededor de 0, no se identifican patrones dentro de las graficas de estudentizados vs valores ajustados lo que indica que no hay problema de varianza constante. 

2) Se evidencian valores alejados de la nube de puntos, en un principio se perciben puntos atipicos(estan por encima de 3). Por ejemplo, en la grafica de EDAD vs Residuales estudentizados, se ve claramente un valor en aproximadamente x= 60 que toma valores cercanos a 6. En general todas las graficas muestran un punto atípico.

3) se observan algunos puntos alejados en direccion del eje x que da indicios de la existencia de puntos de balanceo, como en la grafica de NENFERM, valores >600. 

4) No se observan puntos influenciales a primera vista, sin embargo en la gráfica de residuales estudentizados vs valores ajustados se puede pensar que la observación atípica tambíen es un punto influencial. 

Graficamente se da una aproximación de diagnosticos acerca del modelo, sin embargo estos se deben respaldar con pruebas estadisticas.


6. **Gráfico de normalidad** 

$$H_0:\space \varepsilon_i\space	\sim N(0,\sigma^2)$$

$$H_1:\space \varepsilon_i\space	\nsim N(0,\sigma^2)$$


```{r, echo=FALSE, fig.align = "center", fig.height = 6, fig.width = 6, out.width = "70%"}
test=shapiro.test(rstudent(modelo)) #Test de normalidad sobre residuales estudentizados
qqnorm(rstudent(modelo),cex=2)
qqline(rstudent(modelo),col=4)
legend("topleft",legend=rbind(c("Statistic W","p.value"),round(c(test$statistic,test$p.value),digits=5)),cex=1.2)
```

En un principio los residuales se ajustan a la línea azul que representa el ajuste de la distribución de los residuales a una distribución normal, se podría asegurar normalidad, sin embargo, esta normalidad se ve afectada por el dato atipico del extremo derecho por lo que en la prueba de normalidad de Shapiro Wilk no se cumple el criterio de normalidad. se recomienda realizar un analisis de observaciones anomalas. 

7. **Tabla de diagnosticos**

```{r, echo=FALSE}
    # Cálculo de errores estándar de los valores ajustados
    se.yhat <- predict(modelo, se.fit = T)$se.fit
    
    # Residuales crudos del modelo
    residuals <- round(modelo$residuals, 4)
    
    #res.stud
     ei <- round(rstandard(modelo), 4)
    
    ##rstudent
     ri <- round(rstudent(modelo), 4) 
     
    
    # Valores de la diagonal de la matriz H
    hii.value <- round(hatvalues(modelo), 4)
  

  
    # Tabla de diagnósticos
    data.frame(Y = DPERM, ri, ei, se.yhat, residuals, hii.value)
    ```

**Observaciones atipicas**

Se asume que la observación i es atipica si un ei grande (|ei| > 3) y Se considera potencialmente atipica con ri grande (|ri| > 3)
Deacuerdo a la columna ei y ri se observa que la observación 19 es atípica.

**Observaciones de balanceo**

Se asume que la observación i es un punto de balanceo si hii > 2p/n.
En esta práctica tenemos como criterio que: hii > 2(k+1)/n = 2(9/80) = 0.225.
De acuerdo a la columna hii.value la observación 

* 2=0.3116
 * 18=0.2452
  * 20=0.5457
   * 22=0.46

* 34=0.2363
 * 54=0.3105
  * 74=0.2689 

son puntos de balanceo

**Observaciones influenciales**

```{r, echo=FALSE}
influence.measures(modelo)$is.inf
```


Para identificar estos valores utilizaremos 3 criterios, que son:

* Se dice que la observacion sera influencial si Di > 1.
 * una observacion sera influencial si |DFFITS| > 2(p/n)^0.5
  * observaciones con un covratio tal que |COVRATIO-1| > 3(p/n)
son cadidatas a ser influenciales 

* De acuerdo a la columna Cooks.D de distancias de Cook tenemos que la observacion 19 es influencial
 * De acuerdo a la columna Dffits de valores DFFITS tenemos que las observaciones 
   19 y 22 son influenciales.
  * De acuerdo a la columna Covratio de observaciones covratio tenemos que 2,3,14,18,19,20,22,34,49,52 son influenciales 
  
Se eliminan aquellos datos que toman valores muy por encima de la cota de cada regla. Por ejemplo la obvervacion 20 tiene un valor en el hii de 0.5457 y para no considerarse punto de balanceo debe ser inferior a 0.225

La diferencia es sustancial si comparamos respecto a los otros datos que resultaron ser observaciones de balanceo por este metodo, pero se selecciona el dato mas elevado (y que sea necesariamente muy por encima del criterio). La misma idea ha sido plasmada en la seleccion de cada dato atipico, de esta manera se tiene como observacion anomala los datos 19 y 20. (atipico y balanceo)
 
Las observaciones con ID=47 y ID=112 corresponden con las observaciones 19 y 20 respectivamente, según el análisis anterior se observa que la observación 20 es un punto de balanceo esto quiere decir que es una observacion en el espacio de las predictorias alejada del resto de la muestra y que puede controlar ciertas propiedades del modelo ajustado, además se tiene que la observación 20 y 19 son también puntos influenciales osea que tienen un impacto notable sobre los coeficientes de regresión ya que jalan el modelo a su dirección, tambien se observa que la observación 19 es un dato atipico que puede afectar el ajuste del modelo de regresión, en general la observación 19 podría generar un impacto notable negativo al modelo ya que es un punto atipico, de balanceo e influencial.

\newpage

**Gráficas de chequeos y diagnosticos**
 
```{r, echo=FALSE}

jhs =infIndexPlot(modelo)

```

1) En la primera gráfica de distancias de cook, se observa que ningún valor es mayor a 1, por lo tanto no se puede concluir puntos de balanceo.

2) la segunda y tercer grafica muestra a el punto 19 como un punto atipico. La observacion numero 49 aparece con un valor alto pero no lo suficiente para considerarla como un dato atipico. 

3) En la gráfica de hat.values se ve que la observación 20 y 22 que están por encima de 0.4, por lo tanto son puntos de balanceo




```{r, echo=FALSE}
influencePlot(modelo,xlim=c(0,1),ylim=c(-6.0,4.5))
```
 En el grafico circular, se confirma la presencia de puntos de balanceo, en particular las observaciones 20 y 22 que estan significativamente alejadas del resto (en el eje horizontal). Ademas, el circulo correspondiente a la observacion 19 se aleja muy por encima de los demás, ratificando su condicion de dato atipico.


Las observaciones con ID=47 y ID=112 corresponden con las observaciones 19 y 20 respectivamente, por todo lo anterior mencionado en el análisis anterior se observa que la observación 20 es un punto de balanceo esto quiere decir que es una observacion en el espacio de las predictorias alejada del resto de la muestra y que puede controlar ciertas propiedades del modelo ajustado, además se tiene que la observación 20 y 19 son también puntos influenciales osea que tienen un impacto notable sobre los coeficientes de regresión ya que jalan el modelo a su dirección.

**Modelo sin observaciones 19 y 20**
```{r, echo=FALSE}
datar=data[-c(19:20),]
modelor=lm(DPERM~EDAD+RINF+RRC+RRX+NCAMAS+PDP+NENFERM+FSD,data = datar)
summary(modelor)
```

En efecto, existe un cambio sustancial en los parametros del modelo ajustado sin las observaciones exlcuidas, esto puede explicarse dado que la observación 19 era un punto atipico. 

* El error estandar resitual pasó de 1.366 a 1.11
* El R^2 ajustado pasó de 0.5829 a 0.4792

La proporcion de variabilidad que el modelo ajustado explica en los datos disminuyó a un 47%, sin embargo; el residual estimado tambien disminuyó.

\newpage

**Normalidad modelo reducido**

```{r, echo=FALSE, fig.align = "center", fig.height = 6, fig.width = 6, out.width = "70%"}
test=shapiro.test(rstudent(modelor)) #Test de normalidad sobre residuales estudentizados
qqnorm(rstudent(modelor),cex=2)
qqline(rstudent(modelor),col=4)
legend("topleft",legend=rbind(c("Statistic W","p.value"),round(c(test$statistic,test$p.value),digits=5)),cex=1.2)
```


Ahora, los datos se ajustan mejor a la linea (cerca de un 97%), acorde a la prueba de Shapiro-Wilk; se concluye que sin las obsrevaciones 19 y 20, los residuos del modelo ajustado se distribuyen normal y se confirma que la observación 19 afectaba la prueba de Shapiro-Wilk. 

NOTA: Profe, le deseo suerte calificando estos trabajos. Si este es largo, no me imagino como serán los otros. Exitos y fuerza en esta tarea tan larga.

8. **Multicolinealidad para modelo full**



**Matriz de correlación de variables predictorias**
```{r, echo=FALSE}
cor(data)
```

Se detecta una asociación lineal entre NCAMAS y PDP, NCAMAS y NENFERM, NCAMAS y FSD, PDP y NENFERM, FSD y PDP, FSD y NENFERM porque nos da un valor de correlación de 0.9793, 0.9111,0.7545, 0.887, 0.7346 y 0.7747 respectivamente.

**VIF'S**
Para analizar problemas de multicolinealidad con los VIF's, se analiza la siguiente tabla:

```{r, echo=FALSE}
vif(modelo)
```
Para VIF's con valores >10 indica que hay problemas de multicolinealidad. Según este criterio se detecta problemas de multicolinealidad  ya que la variable PDP tiene un valor de 25.56. 

**Proporciones de varianza**

Como en los datos $\beta_0$ no tiene interpretabilidad, se trabaja con los datos centrados. Para ello:


```{r,echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
Ind=colldiag(modelo,center=TRUE)
X=model.matrix(modelo)[,-1]
val.prop=prcomp(X,center=TRUE,scale=TRUE)$sdev^2
resul=data.frame(Val.propio=val.prop,Ind.Cond=Ind$condindx,Pi=Ind$pi)
resul
```


Segun el indice de condicion, existe problemas graves de multicolinealidad si dicho indice es mayor de 31. En ninguna de estas variables hay problemas graves de multicolinealidad. Ahora, hay un valor (octava fila) de casi 15. Esto implica que hay problemas leves de multicolinealidad.

Las otras columnas representan la descomposicion de varianzas para cada una de las variables y, se dice que existe problemas de multicolniealidad entre dos variables cuando los valores superen 0.5

De esta manera se tiene que existe problemas de multicolinealidad entre RINF y RRC pues los dos valores anexos en su quinta fila superan 0.5 (0.611176182 y 0.653776646)

Finalmente se concluye que existen problemas de multicolinealidad leve entre las variables RINF y RRC. 

\newpage

**Multicolinealidad para modelo sin observaciones 19 y 20**

**Matriz de correlación de variables predictorias**

```{r,echo=FALSE}
cor(datar)
```

Se detecta una asociación lineal entre NCAMAS y PDP, NCAMAS y NENFERM, NCAMAS y FSD, PDP Y NENFERM, FSD y PDP, FSD y NENFERM ya que presentan valores de correlación de 0.98399790,0.91627723,0.75876374, 0.916277230, 0.758493360 y  0.7699048 respectivamente.

**VIF'S**

```{r, echo=FALSE}
vif(modelor)
```

Para VIF's con valores >10 indica que hay problemas de multicolinealidad.Según este criterio se detecta problemas de multicolinealidad en almenos dos variables ya que tiene un valor de 34.359(PDP) Y 34.3407(NCAMAS) respectivamente sin embargo, no se tiene certeza de cuales son las que presentan dicho problema.

**Proporciones de varianza**

```{r, echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
Ind=colldiag(modelor,center=TRUE)
X=model.matrix(modelor)[,-1]
val.prop=prcomp(X,center=TRUE,scale=TRUE)$sdev^2
resul=data.frame(Val.propio=val.prop,Ind.Cond=Ind$condindx,Pi=Ind$pi)
resul
```
Segun el indice de condicion existe problemas de multicolinealidad leve en la fila 8, ya que toma un valor de 15.7502>10, hay problemas de multicolinealidad entre RINF y RRC pues los dos valores anexos en su quinta fila superan 0.5 (0.574578220	 y 0.638148976)

Finalmente se concluye que existen problemas de multicolinealidad leve entre las variables RINF y RRC.

En terminos generales los problemas de multicolinealidad no mejoraron sin las observaciones 19 y 20, pues en ambos modelos hay presencia de multicolinealidad leve entre las variables RINF(Riesgo de infección) y RRC(Razón de rutina de cultivos.)

9. **Selección de variables**

Bajo el modelo ajustado sin las observaciones, se procede a realizar el analisis correspondiente al mejor modelo a ajustar acorde a los criterios solicitados.

comparando todos los posibles modelos y teniendo siempre presente el principio de parsimonia:

 * Por criterio de $R^2_{adj}$ y $R^2$, se selecciona el modelo con el valor mas alto
 
 * Por ciriterio de MSE se selecciona el modelo con menor valor de este estadistico, aunque es equivalente con el anterior (A menor MSE mayor $R^2_{adj}$ y $R^2$ asi que se esperan resultados similares)
 
 * Por criterior de $C_p$ para el valor mas pequeño de dicho estadistico; estadistico que está dado por:
 
 $$ C_p=\frac{SSE_p}{MSE(X_1,X_2,...,X_k)}-(n-2p)$$ 
 
 Donde $SSE_p$ es el SSE del moderlo de regresion con $p-1\leq k$ variables predictoras y el MSE del denominador es el SSE con todas las k predictoras. 
 

```{r, echo=FALSE}
k = ols_step_all_possible(modelor);k
```

Con esto en mente, se seleccionaria acorde a los criterios mencionados; sin embargo, revisar uno a uno los criterios de la tabla puede ser un trabajo poco efectivo y engorroso. Para ello, se apoya en la siguiente grafica:

```{r echo=FALSE}
plot(k)
```

Donde en el eje x se encuentra el numero de covariables tomadas y en el eje Y se representa el valor de cada prueba. 
 
# $R^2$ y $R^2_{adj}$: 

Se seleccionan como candidatos los valores resaltados en las graficas anteriores siguiendo las indicaciones de los criterios, de esta manera se tiene que:
 
Bajo el criterio del R cuadrado, con 6 variables el modelo 219 es: 0.52289792	

Bajo el criterio del R cuadrado ajustado, con 6 variables el modelo 219 es: 0.48257944

Bajo el criterio del R cuadrado, con 7 variables el modelo 247 es: 0.53241491

Bajo el criterio del R cuadrado ajustado, con 7 variables el modelo 247 es: 0.48565640

Bajo el criterio del R cuadrado, con 5 variables el modelo 163 es: 0.51227067

Bajo el criterio del R cuadrado ajustado, con 5 variables el modelo 163 es: 0.47840058

Al analizar todos los posibles valores del R cuadrado y ajustado, el mejor modelo a tener en cuenta es el modelo 163 que incluye a las variables EDAD, RINF, RRX, PDP y NENFERM debido a que los otros modelos tienen valores ligeramente mas altos pero no es una diferencia representativa. 

NOTA: Se seleccionan los modelos 219,247 y 163 debido a que son los valores mas altos de esta medida, teniendo en cuenta el principio de parsimonia, intentando tener los valores mas altos de R con el menor numero de variables.

**Estadistico Cp**

Por este criterio, en la grafica buscamos los valores mas pequeños y nuveamente se resaltan los modelos 163,219, 247 y 255. Analizando dichos modelos en la tabla anterior se tiene que:


 Para el modelo 163 es |6.108121-6|= 0.108121
 
 Para el modelo 219 es |6.536940-7| = 0.46306
 
 Para el modelo 247 es |7.129905-8| = 0.870095
 
 Para el modelo 255 es |9.0-9| = 0
 
Teniendo en cuenta que se busca el minimo valor de Cp y minimo de la resta; Bajo este criterio, se selecciona nuevamente el modelo 163; correspondiente a las variables EDAD, RINF, RRX, PDP y NENFERM.


Como en ambos metodos el modelo ajjustado 163 es este: 

```{r, echo=FALSE}
modelo_163=lm(DPERM~EDAD+RINF+RRX+PDP+NENFERM,data = datar)
summary(modelo_163)
```

De este modelo, se muestran los parametros estimados y demas valores.

```{r,echo=FALSE}
Anova(modelo_163)
```

Nota: Teniendo en cuenta que dentro de un modelo, se busca la eficiencia basado en el principio de parsimonia; el modelo resultante Incluye una variable que no es significativa a un nivel de 0.05. sin embargo, dicha variable no es significativa por muy poco (pues es de casi 0.06 y la significancia es de 0.05).

Se recomienda interrogar al experto para buscar claridad en esta cuestión específica pues, el podría reconocer o no la importancia de la variable NENFERM; dependiendo de esto se podría eliminar esta variable.

**Seleccion Forward**

Este metofo ajusta primero al modelo aquella $X_j$ que sea estadisticamente significativa al modelo con menor error MSE (Con el p-valor) y asi, se agregan variables una a una hasta ir reduciendo significativamente el SSE en presencia de las que ya estan en el modelo. 

**Seleccion backward**

Este metodo parte del modelo FULL a trabajar y de este, se seleccionan una a una variables $X_j$ que no resulten significativa al modelo (la que menos), de tal manera que al eliminarla se reduzca el SSE, en presencia de las demas. 


**Seleccion StepWise**

Combinacion de los dos metodos anteriores. Comienza agregando variables una a la vez segun el metodo forward (segun las mas significativas).

Una vez agregada una nueva variable, utilizar backward para verificar que todas las variables presentes son significativas.

Y se detiene el proceso cuando ya todas las variables son significativas. 


*Para este caso, se fija un $\alpha = 0.05$*

Teniendo en cuenta que cada una de las selecciones para cada metodo se basa en las pruebas F de significancia de las variables, de esta manera; se tiene que:

*Step Backward*
```{r echo=FALSE}

# Step backward

#ols_step_backward_p(modelor,prem = 0.05,details = T)

ols_step_backward_p(modelor,prem = 0.05)

#ols_step_backward_p(modelor,prem = 0.05)$model

# Asi se saca los coeficientes del modelo, para no tener eso tan largo

```
Despues de realizas la seleccion de variables a traves del metodo backward, el modelo de regresion resultante tiene a las variables EDAD, RINF, RRX y PDP; pues en esta tabla se muestran las variables removidas del modelo FULL (FSD,NCAMAS,RRC,NENFERM).

Se tienen las medidas resumenes calculadas anterior mente para un modelo con estas covariables. 

```{r echo=FALSE}
modelo_backward = ols_step_backward_p(modelor,prem = 0.05)$model
summary(modelo_backward)
```
El modelo ajustato tendrá los anteriores coeficientes y su ANOVA será:

```{r echo=FALSE}
Anova(modelo_backward)

```

De lo anterior, como resultado se tiene un modelo con 4 variables predictoras, un $R^2$ de 0.4879 y el ajustado de 0.4598. Esto implica que el modelo explica aproximadamente entre un 49 y un 46% de la variabilidad total existente (dependiendo de que medida se tome en cuenta) ademas, Los residuales son de  1.13


*Step Forward*


```{r echo=FALSE}
#ols_step_forward_p(modelor, penter = 0.05 , details  = T)
ols_step_forward_p(modelor, penter = 0.05 )
```

Finalmente, el modelo resultante es el dado en la tabla resumen. A traves del metodo de seleccion forward y backward se llega al mismo modelo. Si se compara los coeficientes del modelo ajustado por el metodo Backward:


```{r echo=FALSE}
ols_step_forward_p(modelor, penter = 0.05 )$model
```
Se comprueba que el modelo es exactamente el mismo, con sus medidas de interes iguales.

*Step Stepwise*

```{r echo=FALSE}
ols_step_both_p(modelor,pent = 0.05,prem = 0.05)
#ols_step_both_p(modelor,pent = 0.05,prem = 0.05, details = TRUE)
```

Finalmente con stepwise se llega al mismo modelo ajustado, concluyendo que todas las pruebas resultantes coinciden en que, el mejor modelo a ajustar es el ya calculado. 

```{r echo=FALSE}
ols_step_both_p(modelor,pent = 0.05,prem = 0.05)$model
```


$$Y = \beta_0 +\beta_1X_{i1}+\beta_2X_{i2}+\beta_3X_{i3}+\beta_4X_{i4}+ \varepsilon_i\space$$ $$\space \varepsilon_i\space	\sim N(0,\sigma^2)$$

Entonces, reemplazando los coeficientes estimados, el modelo finalmente es:

$$Y = 1.199063  +0.476710X_{i1}+0.078983X_{i2}+0.017938X_{i3}+0.002585X_{i4+} \varepsilon_i\space$$$$\space \varepsilon_i\space	\sim N(0,\sigma^2)$$

* $X_1$ es la variable RINF
 * $X_2$ es la variable EDAD
  * $X_3$ es la variable RRX
   * $X_4$ es la variable PDP

10. **Seleccion del modelo**

Para seleccionar el modelo mas optimo, se debe de realizar una comparativa de los posibles modelos resultantes a trabajar, en este caso, el modelo 163 y el modelo resultante de los metodos de seleccion recien hechos (forward, backward, stepwise).

**Pruebas sobre el nuevo modelo** 

Se deben de realizar pruebas sobre este modelo para verificar que cumpla todos los supuestos y sea un modelo optimo a trabajar.

El modelo a ajustar (acorde a lo ya realizado) es el siguiente:

```{r}
modelo_final =lm(DPERM~EDAD+RINF+RRX+PDP,data = datar)
summary(modelo_final)
```

Se muestran, nuevamente los parametros estimados del modelo en la primera columna, rapidamente; con una significancia del 0.05; se puede ver los p-values en la ultima columna, que ayudan a probar significancia de los parametros(Lo cual es consistente, pues gracias a las pruebas de eliminacion de variables; el modelo ha sido construido de tal manera que las variables sean significativas tanto global como parcialmente)

De esta manera, se desea probar la significancia global del modelo (pues la individual de los parametros ya ha sido probada)

*Significancia global:*

El modelo planteado es de la forma:
$$Y_i = \beta_0 + \beta_1X_{i1} + \beta_2X_{i2} + \beta_3X_{i3}+\beta_4X_{i4} + \varepsilon_i, \quad i = 1, 2, \ldots, 80$$
Que tiene como supuestos lo siguiente:
$$\varepsilon_i \overset{\text{iid}}{\sim} N\left(0,\sigma ^2 \right), \quad i = 1, 2, \ldots, 80$$
$$
\begin{aligned}
H_0:&\ \beta_1 = \beta_2 = \cdots = \beta_4 = 0, \quad \text{ vs.}\\
H_1:&\ \text{Algún } \beta_j \neq 0, j = 1, \ldots, 4.
\end{aligned}
$$
Para ello se usa la tabla de análisis de varianza. De ella se obtienen los valores del estadístico de prueba $F_0 =14.7988$ y su correspondiente valor-P $\text{vp} = 1.68478e-12$.
    
Como vp $< 0.05 = \alpha$ se rechaza $H_0$ concluyendo que el modelo de RLM propuesto es significativo. Esto quiere decir, que la logitud de permanencia es afectada significativamente por al menos una de las predictoras consideradas.

    ```{r, echo=FALSE, warning=FALSE, comment=FALSE, results="asis", message=FALSE, size=20}
   # ANOVA
   myAnova(modelo_final)
  
    ```

Para ello se usa la tabla de análisis de varianza. De ella se obtienen los valores del estadístico de prueba $F_0 =17.3869$ y su correspondiente valor-P $\text{vp} = 	4.63553e-10$.
    
Como p-value $< 0.05 = \alpha$ se rechaza $H_0$ concluyendo que el modelo de RLM propuesto es significativo. Esto quiere decir, que la logitud de permanencia es afectada significativamente por al menos una de las predictoras consideradas.

*Coeficiente de determinacion:*

De la tabla resumen del modelo se obtiene rapidamente que los valores de $R^2 \space y \space R^2_{adj}$ son 0.4879 y 0.4598 respectivamente.

El modelo ajustado con las 4 variables selecionadas explica segun estas cifras, un 48.79 y 45.98 % de la varianza total. Nuevamente, se concluye que hace falta una "variable clave" para dar una respuesta optima al problema, pues aun, despues de todos los analisis y pruebas realizadas, el modelo final "abarca" un porcentaje bajo de la variabilidad total como para considerarse como un buen modelo. 

Se recomienda tomar mas datos, muestreando nuevas variables a tener en cuenta. 

*Variables mas influyentes*

Se desea saber cual variable/s tienen mas influencia en el modelo final. Para ello:

```{r}

miscoeficientes(modelo_final,datar)
```

Al observar los coeficientes estandarizados se sabe que, la magnitud del valor absoluto de la variable con mayor valor será la más influyente. De esta forma:

* La variable RINF es la mas influyente para la variable respuesta DPERM

* La variable PDP es la menos influyente para la variable respuesta DPERM

*Prueba de significancia individual de los parametros:*

Se procede a probar la significancia individual de los parametros. Estas pruebas establecen el siguiente juego de hipótesis:
$$\begin{array}{l} H_0: \beta_j = 0\\ H_1: \beta_j \ne 0 \end{array}\ \text{ para }\ j = 1, 2, \ldots, 4.$$

De la tabla de parámetros estimados, a un nivel de significancia $\alpha = 0.05$ se rechaza $H_0$ si $\left | T_0 \right |> T_\frac{\alpha }{2} ,n-k-1$

Para este caso con la $T_{(1-\frac{0.05}{2},75)}=1.992102$ basta comparar con los datos suministrados en la tabla anterior en la columna de t-values (note, nuevamente que este modelo fue creado de tal manera que cada parametro sea significativo, esta prueba lo ratifica):

* $EDAD=\left | 2.767   \right |$ > 1.992102
* $RINF=\left | 4.114\right |$ > 1.992102
* $RRX=\left | 2.5110  \right |$ > 1.992102
* $PDP=\left | 2.490 \right |$ > 1.992102

concluye que los parámetros individuales $\beta_1,\beta_2,\beta_3, \beta_4$ son significativos cada uno en presencia de los demás parámetros. 
$\widehat\beta_1 = 0.078983$ indica que por cada unidad de aumento en la edad el promedio de la longitud de permanencia aumenta en 0.078983 unidades, cuando las demás variables predictoras se mantienen fijas. 

$\widehat\beta_2 = 0.476710$ indica que por cada unidad de aumento en el riesgo de infección el promedio de la longitud de permanencia aumenta en 0.476710 unidades, cuando las demás variables predictoras se mantienen fijas.

$\widehat\beta_3 = 0.017938$ indica que por cada unidad de aumento en la razón de rutinas de rayos X en el pecho el promedio de la longitud de permanencia aumenta en 0.017938 unidades, cuando las demás variables predictoras se mantienen fijas.

$\widehat\beta_4 = 0.002585$ indica que por cada unidad de aumento en el censo promedio diario el promedio de la longitud de permanencia aumenta en 0.002585  unidades, cuando las demás variables predictoras se mantienen fijas.


**Suma de cuadrados Tipo I**

```{r, echo=FALSE}
wo_ai_ni=anova(modelo_final)
wo_ai_ni["Sum Sq"]
```
La suma de cuadrados extra tipo I  agregada secuencialmente las variables según el orden establecido en el modelo full, es decir:

1) $SSR(EDAD)=12.515$ Y este es el resultado de ajustar la recta de regresio (Suma de cuadrados de la regresion) 
$Y_i= \beta_0+\beta_1*X_{i1}$ que es Longidtud de permanencia (DPERM) vs Edad

2) $SSR(RINF|EDAD)= 61.736$ Este es el incremento de SSR (Suma de cuadrados de la regresion) al ingresar la variable RINF al modelo de la longitud de permanencia (DPERM) vs EDAD.

3) $SSR(RRX|EDAD,RINF)= 6.704$ Este es el incremento de SSR (Suma de cuadrados de la regresion) al ingresar la variable RINF al modelo de la longitud de permanencia (DPERM) vs EDAD.

3) $SSR(PDP|EDAD,RINF,RRX)= 7.923$ Este es el incremento de SSR (Suma de cuadrados de la regresion) al ingresar la variable RINF al modelo de la longitud de permanencia (DPERM) vs EDAD.


Teniendo en cuenta que se busca que el SSR sea mayor Y el SSE sea menor aqui se obvserva el efecto parcial de ir agregando cada nueva variable de manera secuencial, comenzando en X1 y terminando con X4.

En este caso al ingresar la ultima covariable se presento la menor reducción marginal en la suma de cuadrados extras cuando las demás predictorias fueron agragadas al modelo. 

**Suma de cuadrados tipo II**
```{r, echo=FALSE}
smith2 = Anova(modelo_final)
smith2[1]
```
En este caso, se parte del modelo con todas las variables y se agrega una covariable, la idea es analizar el cambio que tiene en el modelo cada una de esta dado que en el modelo ya se encuentran las otras covariables (todas).

Se nota que en efecto, la variable con menor suma de cuadrado es PDP, indicando ser una que minimiza.

**Graficos de residuales estudentizados vs valores ajustados**

```{r, echo=FALSE}
residualPlots(modelo_final,tests=FALSE,type="rstudent",quadratic=FALSE,col=4,cex=1.0)
```
**Interpretación**

1) Se observa que los datos son aleatorios alrededor de 0, no se identifican patrones dentro de las graficas de estudentizados vs valores ajustados lo que indica que no hay problema de varianza constante. 

2) Se evidencian valores alejados de la nube de puntos, en un principio se perciben puntos atipicos(estan por encima de 3). Por ejemplo, en la grafica de EDAD vs Residuales estudentizados, se ve claramente un valor en aproximadamente x= 45 que toma valores cercanos a 3. En general todas las graficas muestran un punto por encima de 3.

3) se observan algunos puntos alejados en direccion del eje x que da indicios de la existencia de puntos de balanceo

4) No se observan puntos influenciales a primera vista. 

Graficamente se da una aproximación de diagnosticos acerca del modelo, sin embargo estos se deben respaldar con pruebas estadisticas.

**Gráfico de normalidad** 
Se desea probar que:
$$H_0: Errores\space \varepsilon_i\space	\sim N(0,\sigma^2)$$

$$H_1:\space \varepsilon_i\space	\nsim N(0,\sigma^2)$$

```{r, echo=FALSE, fig.align = "center", fig.height = 6, fig.width = 6, out.width = "70%"}
test=shapiro.test(rstudent(modelo_final)) #Test de normalidad sobre residuales estudentizados
qqnorm(rstudent(modelo_final),cex=2)
qqline(rstudent(modelo_final),col=4)
legend("topleft",legend=rbind(c("Statistic W","p.value"),round(c(test$statistic,test$p.value),digits=5)),cex=1.2)
```

Los puntos sobre la recta no se ajustan lo suficiente para asegurar normaliad. De hecho, en los extremos, claramente los puntos se alejan de la recta lo que incita a sospechar sobre problemas de normalidad en los errores. 

El valor p dado en la grafica es cero (0) por tanto, segun test shapiro wilk,se rechaza hipotesis nula y se concluye que en este caso, los errores no se distribuyen normal.

Este problema en la normalidad de los errores podria estar dado a observaciones atipicas.

**Tabla de diagnosticos**

```{r, echo=FALSE}
    # Cálculo de errores estándar de los valores ajustados
    se.yhat <- predict(modelo_final, se.fit = T)$se.fit
    
    # Residuales crudos del modelo
    residuals <- round(modelo_final$residuals, 4)
    
    #res.stud
     ei <- round(rstandard(modelo_final), 4)
    
    ##rstudent
     ri <- round(rstudent(modelo_final), 4) 
     
    
    # Valores de la diagonal de la matriz H
    hii.value <- round(hatvalues(modelo_final), 4)
    
    # Distancias de Cook
    Cooks.D <- round(cooks.distance(modelo_final), 4)
  
    # Dffits
    Dffits <- round(dffits(modelo_final), 4)
    
        ##covaratio
    Covratio <- round(covratio(modelo_final), 4)
  
    # Tabla de diagnósticos
    data.frame(datar$DPERM,ri, ei, se.yhat, residuals, Cooks.D, hii.value, Dffits, Covratio)
    ```

**Observaciones atipicas**

Se asume que la observación i es atipica si un ei grande (|ei| > 3) y Se considera potencialmente atipica con ri grande (|ri| > 3)
Deacuerdo a la columna ei y ri se observa que la observación 19 es atípica.

Se tiene que la observacion 49 es atipica.

**Observaciones de balanceo**

Se asume que la observación i es un punto de balanceo si hii > 2p/n = 0.1282051

De acuerdo a la columna hii.value la observación 2 (0.2210),18 (valor muy alto, de 0.2179
),26,34 (valor de 0.1855),37 (0.1470) y 74 (0.1719) son puntos de balanceo.

Se sospecha, particularmente de la observacion 2 y 18.

**Observaciones influenciales**

Para identificar estos valores utilizaremos 3 criterios, que son:

* Se dice que la observacion sera influencial si Di > 1. Segun esto, no hay datos influenciables.

* una observacion sera influencial si |DFFITS| > 2(p/n)^0.5 = 0.5063697

Segun esto, la observacion 7(0.5556),8(0.5480),18(0.6401),26(-0.6773),34(0.7145),49(0.8779),54(-0.5153) y 65(0.6884) son influenciables.

* observaciones con un covratio tal que |COVRATIO-1| > 3(p/n) =0.1923077 

Segun esto, la observacion 2(0.3616),8(0.2288),18(0.2381),33(0.2072),37(0.2208),49(0.4255),63(0.2074) y 74(0.2935)


**Gráficas de chequeos y diagnosticos**
 
```{r, echo=FALSE}

dig_final =infIndexPlot(modelo_final)

```

1) En la primera gráfica de distancias de cook, se observa que ningún valor es mayor a 1, por lo tanto no se puede concluir puntos de balanceo.

2) En la segunda y tercer grafica se muestra a el dato 49 como atipico, habiendo valores altos, como el 8.

3) En la gráfica de hat.values se ve que la observación 18 y 22 que están por encima de 0.4, por lo tanto son puntos de balanceo


```{r}
influencePlot(modelo_final,xlim=c(0,1),ylim=c(-6.0,4.5))
```
Nuevamente, se observan algunos datos ligeramente por encima de los Hat-values como el 34 y 18 pero no se alejan demasiado de los datos. Ademas a la  observacion 49 como atipica. 

al verificar que no son errores de digitacion, se procede a eliminar la observacion 49.


```{r, echo=FALSE}
data_final= data[-c(19,20,49),]
modelo_super_final=lm(DPERM~EDAD+RINF+RRX+PDP,data = data_final)
summary(modelo_super_final)
```

Estos son los nuevos parametros con los nuevos datos, sin la observacion 49. Verificando normalidad tenemos que:

```{r, echo=FALSE, fig.align = "center", fig.height = 6, fig.width = 6, out.width = "70%"}
test=shapiro.test(rstudent(modelo_super_final)) #Test de normalidad sobre residuales estudentizados
qqnorm(rstudent(modelo_super_final),cex=2)
qqline(rstudent(modelo_super_final),col=4)
legend("topleft",legend=rbind(c("Statistic W","p.value"),round(c(test$statistic,test$p.value),digits=5)),cex=1.2)
```
 Al eliminar la observacion 49, los residuales ahora se distribuyen normal estandar. Este dato atipico afectava negativamente la normalidad de los residuos. 
 
 En efecto, existe un cambio sustancial en los parametros del modelo ajustado si la observacion exlcuida, esto puede explicarse dado que la observación 49 era un punto atipico. 

* El error estandar resitual pasó de 1.13 a 1.062
* El R^2 ajustado pasó de 0.4598 a 0.5209 

La proporcion de variabilidad que el modelo ajustado explica en los datos aumentó a el 52%

*Analisis multicolinealidad:*


```{r, echo=FALSE}

vif(modelo_super_final)

```
Segun los VIFF's, no existe ningun tipo de multicolinealidad en las variables seleccionadas. 

```{r, echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
Ind=colldiag(modelo_super_final,center=TRUE)
X=model.matrix(modelo_super_final)[,-1]
val.prop=prcomp(X,center=TRUE,scale=TRUE)$sdev^2
resul=data.frame(Val.propio=val.prop,Ind.Cond=Ind$condindx,Pi=Ind$pi)
resul
```
Verificando el indice de condicion y la descomposicion de varianzas se comprueba que no hay problemas de multicolinealidad.

Finalmente, una vez probado todos los supuestos, se concluye que este es el modelo optimo que se puede ajustar a los datos obtenidos.


